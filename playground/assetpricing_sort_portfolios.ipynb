{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to render the asset pricing table\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import ttest_1samp\n",
    "from regtabletotext import prettify_result\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from environ.constants import (\n",
    "    DEPENDENT_VARIABLES,\n",
    "    DEPENDENT_VARIABLES_ASSETPRICING,\n",
    "    PROCESSED_DATA_PATH,\n",
    "    STABLE_DICT,\n",
    "    ALL_NAMING_DICT,\n",
    "    TABLE_PATH,\n",
    ")\n",
    "from environ.process.asset_pricing.double_sorting import calculate_period_return\n",
    "\n",
    "from environ.process.asset_pricing.assetpricing_functions import (\n",
    "    reg_fama_macbeth, clean_weekly_panel, univariate_sort, univariate_sort_table, double_sort, double_sort_table, get_dominance_portfolios, significance_stars\n",
    "    )\n",
    "                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/chenb/Desktop/defi-econ/processed_data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROCESSED_DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(\"C:\\\\Users\\\\chenb\\\\Desktop\\\\defi-econ\\\\processed_data\\\\defi-currency-data\\\\panel_main.pickle.zip\", compression=\"zip\"\n",
    "    )\n",
    "df2 = pd.read_pickle(\n",
    "        PROCESSED_DATA_PATH / \"panel_main.pickle.zip\", compression=\"zip\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Inflow_centrality</th>\n",
       "      <th>Outflow_centrality</th>\n",
       "      <th>TVL</th>\n",
       "      <th>volume_in</th>\n",
       "      <th>volume_out</th>\n",
       "      <th>borrow_rate</th>\n",
       "      <th>Supply_share</th>\n",
       "      <th>Borrow_share</th>\n",
       "      <th>...</th>\n",
       "      <th>vol_in_full_len_share</th>\n",
       "      <th>vol_out_full_len_share</th>\n",
       "      <th>vol_inter_full_len_share</th>\n",
       "      <th>volume_ultimate_share</th>\n",
       "      <th>mcap_share</th>\n",
       "      <th>dollar_exchange_rate_log_return_1</th>\n",
       "      <th>dollar_exchange_rate_log_return_vol_1_30</th>\n",
       "      <th>corr_gas</th>\n",
       "      <th>corr_eth</th>\n",
       "      <th>corr_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>270921</td>\n",
       "      <td>5.997500e+04</td>\n",
       "      <td>5.997500e+04</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>12915.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>264268.000000</td>\n",
       "      <td>259201.000000</td>\n",
       "      <td>250631.000000</td>\n",
       "      <td>250631.000000</td>\n",
       "      <td>250631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.435637e+06</td>\n",
       "      <td>2021-12-21 14:46:42.520292096</td>\n",
       "      <td>3.620079e-02</td>\n",
       "      <td>3.613452e-02</td>\n",
       "      <td>1.755144e+07</td>\n",
       "      <td>3.714018e+06</td>\n",
       "      <td>3.714018e+06</td>\n",
       "      <td>2.973474e+228</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>0.128053</td>\n",
       "      <td>-0.012643</td>\n",
       "      <td>0.470409</td>\n",
       "      <td>0.366386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2020-07-01 00:00:00</td>\n",
       "      <td>-1.387779e-16</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-91.140050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.750179</td>\n",
       "      <td>-0.722270</td>\n",
       "      <td>-0.793529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2021-06-19 00:00:00</td>\n",
       "      <td>5.248727e-04</td>\n",
       "      <td>5.691961e-04</td>\n",
       "      <td>1.661683e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.041798</td>\n",
       "      <td>0.051096</td>\n",
       "      <td>-0.151499</td>\n",
       "      <td>0.256397</td>\n",
       "      <td>0.171054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2022-01-10 00:00:00</td>\n",
       "      <td>2.336110e-03</td>\n",
       "      <td>2.386071e-03</td>\n",
       "      <td>7.340146e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.001605</td>\n",
       "      <td>0.075006</td>\n",
       "      <td>-0.016323</td>\n",
       "      <td>0.514685</td>\n",
       "      <td>0.396410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2022-07-15 00:00:00</td>\n",
       "      <td>1.052981e-02</td>\n",
       "      <td>1.053827e-02</td>\n",
       "      <td>2.664867e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.031225</td>\n",
       "      <td>0.111107</td>\n",
       "      <td>0.124685</td>\n",
       "      <td>0.717577</td>\n",
       "      <td>0.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.744965e+09</td>\n",
       "      <td>2023-01-31 00:00:00</td>\n",
       "      <td>9.365245e-01</td>\n",
       "      <td>8.835949e-01</td>\n",
       "      <td>4.162345e+09</td>\n",
       "      <td>2.235346e+09</td>\n",
       "      <td>2.509619e+09</td>\n",
       "      <td>8.055765e+233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.562207</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.482010</td>\n",
       "      <td>0.702048</td>\n",
       "      <td>90.916136</td>\n",
       "      <td>23.905279</td>\n",
       "      <td>0.749242</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.953076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.487909e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.201234e-01</td>\n",
       "      <td>1.201434e-01</td>\n",
       "      <td>1.422194e+08</td>\n",
       "      <td>4.244524e+07</td>\n",
       "      <td>4.251799e+07</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.030092</td>\n",
       "      <td>0.160596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030753</td>\n",
       "      <td>0.030819</td>\n",
       "      <td>0.043661</td>\n",
       "      <td>0.030702</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.488559</td>\n",
       "      <td>0.483993</td>\n",
       "      <td>0.199472</td>\n",
       "      <td>0.309345</td>\n",
       "      <td>0.281059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Volume                           Date  Inflow_centrality  \\\n",
       "count  2.709210e+05                         270921       5.997500e+04   \n",
       "mean   7.435637e+06  2021-12-21 14:46:42.520292096       3.620079e-02   \n",
       "min    0.000000e+00            2020-07-01 00:00:00      -1.387779e-16   \n",
       "25%    0.000000e+00            2021-06-19 00:00:00       5.248727e-04   \n",
       "50%    0.000000e+00            2022-01-10 00:00:00       2.336110e-03   \n",
       "75%    0.000000e+00            2022-07-15 00:00:00       1.052981e-02   \n",
       "max    4.744965e+09            2023-01-31 00:00:00       9.365245e-01   \n",
       "std    8.487909e+07                            NaN       1.201234e-01   \n",
       "\n",
       "       Outflow_centrality           TVL     volume_in    volume_out  \\\n",
       "count        5.997500e+04  2.709210e+05  2.709210e+05  2.709210e+05   \n",
       "mean         3.613452e-02  1.755144e+07  3.714018e+06  3.714018e+06   \n",
       "min         -1.110223e-16  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%          5.691961e-04  1.661683e+05  0.000000e+00  0.000000e+00   \n",
       "50%          2.386071e-03  7.340146e+05  0.000000e+00  0.000000e+00   \n",
       "75%          1.053827e-02  2.664867e+06  0.000000e+00  0.000000e+00   \n",
       "max          8.835949e-01  4.162345e+09  2.235346e+09  2.509619e+09   \n",
       "std          1.201434e-01  1.422194e+08  4.244524e+07  4.251799e+07   \n",
       "\n",
       "         borrow_rate   Supply_share  Borrow_share  ...  vol_in_full_len_share  \\\n",
       "count   2.709210e+05  270921.000000  12915.000000  ...          270921.000000   \n",
       "mean   2.973474e+228       0.003488      0.073171  ...               0.003488   \n",
       "min     0.000000e+00       0.000000      0.000000  ...               0.000000   \n",
       "25%     0.000000e+00       0.000000      0.000171  ...               0.000000   \n",
       "50%     0.000000e+00       0.000000      0.002732  ...               0.000000   \n",
       "75%     0.000000e+00       0.000000      0.029206  ...               0.000000   \n",
       "max    8.055765e+233       1.000000      1.000000  ...               0.861772   \n",
       "std              inf       0.030092      0.160596  ...               0.030753   \n",
       "\n",
       "       vol_out_full_len_share  vol_inter_full_len_share  \\\n",
       "count           270921.000000             270921.000000   \n",
       "mean                 0.003488                  0.003488   \n",
       "min                  0.000000                  0.000000   \n",
       "25%                  0.000000                  0.000000   \n",
       "50%                  0.000000                  0.000000   \n",
       "75%                  0.000000                  0.000000   \n",
       "max                  0.562207                  0.999657   \n",
       "std                  0.030819                  0.043661   \n",
       "\n",
       "       volume_ultimate_share     mcap_share  \\\n",
       "count          270921.000000  270921.000000   \n",
       "mean                0.003488       0.003488   \n",
       "min                 0.000000       0.000000   \n",
       "25%                 0.000000       0.000000   \n",
       "50%                 0.000000       0.000044   \n",
       "75%                 0.000000       0.000289   \n",
       "max                 0.482010       0.702048   \n",
       "std                 0.030702       0.034371   \n",
       "\n",
       "       dollar_exchange_rate_log_return_1  \\\n",
       "count                      264268.000000   \n",
       "mean                           -0.000702   \n",
       "min                           -91.140050   \n",
       "25%                            -0.041798   \n",
       "50%                            -0.001605   \n",
       "75%                             0.031225   \n",
       "max                            90.916136   \n",
       "std                             0.488559   \n",
       "\n",
       "       dollar_exchange_rate_log_return_vol_1_30       corr_gas       corr_eth  \\\n",
       "count                             259201.000000  250631.000000  250631.000000   \n",
       "mean                                   0.128053      -0.012643       0.470409   \n",
       "min                                    0.000000      -0.750179      -0.722270   \n",
       "25%                                    0.051096      -0.151499       0.256397   \n",
       "50%                                    0.075006      -0.016323       0.514685   \n",
       "75%                                    0.111107       0.124685       0.717577   \n",
       "max                                   23.905279       0.749242       0.999667   \n",
       "std                                    0.483993       0.199472       0.309345   \n",
       "\n",
       "             corr_sp  \n",
       "count  250631.000000  \n",
       "mean        0.366386  \n",
       "min        -0.793529  \n",
       "25%         0.171054  \n",
       "50%         0.396410  \n",
       "75%         0.587100  \n",
       "max         0.953076  \n",
       "std         0.281059  \n",
       "\n",
       "[8 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Inflow_centrality</th>\n",
       "      <th>Outflow_centrality</th>\n",
       "      <th>TVL</th>\n",
       "      <th>volume_in</th>\n",
       "      <th>volume_out</th>\n",
       "      <th>borrow_rate</th>\n",
       "      <th>supply_rates</th>\n",
       "      <th>Borrow_share</th>\n",
       "      <th>...</th>\n",
       "      <th>vol_in_full_len_share</th>\n",
       "      <th>vol_out_full_len_share</th>\n",
       "      <th>vol_inter_full_len_share</th>\n",
       "      <th>volume_ultimate_share</th>\n",
       "      <th>mcap_share</th>\n",
       "      <th>dollar_exchange_rate_log_return_1</th>\n",
       "      <th>dollar_exchange_rate_log_return_vol_1_30</th>\n",
       "      <th>corr_gas</th>\n",
       "      <th>corr_eth</th>\n",
       "      <th>corr_sp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>270921</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>5.997500e+04</td>\n",
       "      <td>5.997500e+04</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>2.709210e+05</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>12915.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>270921.000000</td>\n",
       "      <td>264268.000000</td>\n",
       "      <td>259201.000000</td>\n",
       "      <td>250631.000000</td>\n",
       "      <td>250631.000000</td>\n",
       "      <td>250631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021-12-21 14:46:42.520292096</td>\n",
       "      <td>7.435637e+06</td>\n",
       "      <td>3.620079e-02</td>\n",
       "      <td>3.613452e-02</td>\n",
       "      <td>1.755144e+07</td>\n",
       "      <td>3.714018e+06</td>\n",
       "      <td>3.714018e+06</td>\n",
       "      <td>2.973474e+228</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>0.128053</td>\n",
       "      <td>-0.012643</td>\n",
       "      <td>0.470409</td>\n",
       "      <td>0.366386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-07-01 00:00:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.387779e-16</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-91.140050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.750179</td>\n",
       "      <td>-0.722270</td>\n",
       "      <td>-0.793529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-06-19 00:00:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.248727e-04</td>\n",
       "      <td>5.691961e-04</td>\n",
       "      <td>1.661683e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.041798</td>\n",
       "      <td>0.051096</td>\n",
       "      <td>-0.151499</td>\n",
       "      <td>0.256397</td>\n",
       "      <td>0.171054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-01-10 00:00:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.336110e-03</td>\n",
       "      <td>2.386071e-03</td>\n",
       "      <td>7.340146e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.001605</td>\n",
       "      <td>0.075006</td>\n",
       "      <td>-0.016323</td>\n",
       "      <td>0.514685</td>\n",
       "      <td>0.396410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022-07-15 00:00:00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.052981e-02</td>\n",
       "      <td>1.053827e-02</td>\n",
       "      <td>2.664867e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.031225</td>\n",
       "      <td>0.111107</td>\n",
       "      <td>0.124685</td>\n",
       "      <td>0.717577</td>\n",
       "      <td>0.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-01-31 00:00:00</td>\n",
       "      <td>4.744965e+09</td>\n",
       "      <td>9.365245e-01</td>\n",
       "      <td>8.835949e-01</td>\n",
       "      <td>4.162345e+09</td>\n",
       "      <td>2.235346e+09</td>\n",
       "      <td>2.509619e+09</td>\n",
       "      <td>8.055765e+233</td>\n",
       "      <td>0.633147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861772</td>\n",
       "      <td>0.562207</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.482010</td>\n",
       "      <td>0.702048</td>\n",
       "      <td>90.916136</td>\n",
       "      <td>23.905279</td>\n",
       "      <td>0.749242</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.953076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.487909e+07</td>\n",
       "      <td>1.201234e-01</td>\n",
       "      <td>1.201434e-01</td>\n",
       "      <td>1.422194e+08</td>\n",
       "      <td>4.244524e+07</td>\n",
       "      <td>4.251799e+07</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.160596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030753</td>\n",
       "      <td>0.030819</td>\n",
       "      <td>0.043661</td>\n",
       "      <td>0.030702</td>\n",
       "      <td>0.034371</td>\n",
       "      <td>0.488559</td>\n",
       "      <td>0.483993</td>\n",
       "      <td>0.199472</td>\n",
       "      <td>0.309345</td>\n",
       "      <td>0.281059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date        Volume  Inflow_centrality  \\\n",
       "count                         270921  2.709210e+05       5.997500e+04   \n",
       "mean   2021-12-21 14:46:42.520292096  7.435637e+06       3.620079e-02   \n",
       "min              2020-07-01 00:00:00  0.000000e+00      -1.387779e-16   \n",
       "25%              2021-06-19 00:00:00  0.000000e+00       5.248727e-04   \n",
       "50%              2022-01-10 00:00:00  0.000000e+00       2.336110e-03   \n",
       "75%              2022-07-15 00:00:00  0.000000e+00       1.052981e-02   \n",
       "max              2023-01-31 00:00:00  4.744965e+09       9.365245e-01   \n",
       "std                              NaN  8.487909e+07       1.201234e-01   \n",
       "\n",
       "       Outflow_centrality           TVL     volume_in    volume_out  \\\n",
       "count        5.997500e+04  2.709210e+05  2.709210e+05  2.709210e+05   \n",
       "mean         3.613452e-02  1.755144e+07  3.714018e+06  3.714018e+06   \n",
       "min         -1.110223e-16  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%          5.691961e-04  1.661683e+05  0.000000e+00  0.000000e+00   \n",
       "50%          2.386071e-03  7.340146e+05  0.000000e+00  0.000000e+00   \n",
       "75%          1.053827e-02  2.664867e+06  0.000000e+00  0.000000e+00   \n",
       "max          8.835949e-01  4.162345e+09  2.235346e+09  2.509619e+09   \n",
       "std          1.201434e-01  1.422194e+08  4.244524e+07  4.251799e+07   \n",
       "\n",
       "         borrow_rate   supply_rates  Borrow_share  ...  vol_in_full_len_share  \\\n",
       "count   2.709210e+05  270921.000000  12915.000000  ...          270921.000000   \n",
       "mean   2.973474e+228       0.000603      0.073171  ...               0.003488   \n",
       "min     0.000000e+00       0.000000      0.000000  ...               0.000000   \n",
       "25%     0.000000e+00       0.000000      0.000171  ...               0.000000   \n",
       "50%     0.000000e+00       0.000000      0.002732  ...               0.000000   \n",
       "75%     0.000000e+00       0.000000      0.029206  ...               0.000000   \n",
       "max    8.055765e+233       0.633147      1.000000  ...               0.861772   \n",
       "std              inf       0.006166      0.160596  ...               0.030753   \n",
       "\n",
       "       vol_out_full_len_share  vol_inter_full_len_share  \\\n",
       "count           270921.000000             270921.000000   \n",
       "mean                 0.003488                  0.003488   \n",
       "min                  0.000000                  0.000000   \n",
       "25%                  0.000000                  0.000000   \n",
       "50%                  0.000000                  0.000000   \n",
       "75%                  0.000000                  0.000000   \n",
       "max                  0.562207                  0.999657   \n",
       "std                  0.030819                  0.043661   \n",
       "\n",
       "       volume_ultimate_share     mcap_share  \\\n",
       "count          270921.000000  270921.000000   \n",
       "mean                0.003488       0.003488   \n",
       "min                 0.000000       0.000000   \n",
       "25%                 0.000000       0.000000   \n",
       "50%                 0.000000       0.000044   \n",
       "75%                 0.000000       0.000289   \n",
       "max                 0.482010       0.702048   \n",
       "std                 0.030702       0.034371   \n",
       "\n",
       "       dollar_exchange_rate_log_return_1  \\\n",
       "count                      264268.000000   \n",
       "mean                           -0.000702   \n",
       "min                           -91.140050   \n",
       "25%                            -0.041798   \n",
       "50%                            -0.001605   \n",
       "75%                             0.031225   \n",
       "max                            90.916136   \n",
       "std                             0.488559   \n",
       "\n",
       "       dollar_exchange_rate_log_return_vol_1_30       corr_gas       corr_eth  \\\n",
       "count                             259201.000000  250631.000000  250631.000000   \n",
       "mean                                   0.128053      -0.012643       0.470409   \n",
       "min                                    0.000000      -0.750179      -0.722270   \n",
       "25%                                    0.051096      -0.151499       0.256397   \n",
       "50%                                    0.075006      -0.016323       0.514685   \n",
       "75%                                    0.111107       0.124685       0.717577   \n",
       "max                                   23.905279       0.749242       0.999667   \n",
       "std                                    0.483993       0.199472       0.309345   \n",
       "\n",
       "             corr_sp  \n",
       "count  250631.000000  \n",
       "mean        0.366386  \n",
       "min        -0.793529  \n",
       "25%         0.171054  \n",
       "50%         0.396410  \n",
       "75%         0.587100  \n",
       "max         0.953076  \n",
       "std         0.281059  \n",
       "\n",
       "[8 rows x 47 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'betweenness',\n",
       " 'clustering_ind',\n",
       " 'eigen_centrality_pool',\n",
       " 'eigen_centrality_swap',\n",
       " 'eigen_centrality_undirected',\n",
       " 'eigen_centrality_undirected_multi',\n",
       " 'inflow_centrality',\n",
       " 'inout_flow',\n",
       " 'network_graph',\n",
       " 'outflow_centrality',\n",
       " 'primary_tokens',\n",
       " 'sankey',\n",
       " 'total_eigen_centrality_undirected',\n",
       " 'tvl',\n",
       " 'tvl_old',\n",
       " 'tvl_share',\n",
       " 'tvl_share_old',\n",
       " 'volume',\n",
       " 'volume_in',\n",
       " 'volume_in_share',\n",
       " 'volume_out',\n",
       " 'volume_out_share',\n",
       " 'volume_share',\n",
       " 'volume_total',\n",
       " 'vol_inter_full_len',\n",
       " 'vol_in_full_len',\n",
       " 'vol_out_full_len']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"C:/Users/chenb/Desktop/data/data_network/v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load factors\n",
    "ff3 = pd.read_csv(PROCESSED_DATA_PATH/\"FF3.csv\") \n",
    "ltw3 = pd.read_csv(PROCESSED_DATA_PATH/\"LTW3.csv\")\n",
    "\n",
    "# load the regression panel dataset\n",
    "reg_panel = pd.read_pickle(\n",
    "    PROCESSED_DATA_PATH / \"panel_main.pickle.zip\", compression=\"zip\"\n",
    ")\n",
    "\n",
    "# stable non-stable info dict\n",
    "stable_nonstable_info = {\n",
    "    \"stablecoin\": reg_panel[reg_panel[\"Token\"].isin(STABLE_DICT.keys())],\n",
    "    \"non-stablecoin\": reg_panel[~reg_panel[\"Token\"].isin(STABLE_DICT.keys())],\n",
    "    \"all\": reg_panel,\n",
    "}\n",
    "\n",
    "# How are returns aggregated for each portfolio\n",
    "Q = [0,0.33,0.66,1] # [0,0.2,0.4,0.6,0.8,1]# [0,0.25,0.5,0.75,1]#[0,0.2,0.4,0.6,0.8,1]# \n",
    "ret_agg = 'value_weight' \n",
    "DEPENDENT_VARIABLES_ASSETPRICING = DEPENDENT_VARIABLES_ASSETPRICING[:1] #['volume_ultimate_share']  #,'volume_in_share' , 'volume_out_share']\n",
    "# ,'eigen_centrality_undirected','total_eigen_centrality_undirected','Volume_share']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_13b6b\">\n",
       "  <caption>volume_ultimate_share  alltime</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_13b6b_level0_col0\" class=\"col_heading level0 col0\" >P1</th>\n",
       "      <th id=\"T_13b6b_level0_col1\" class=\"col_heading level0 col1\" >P2</th>\n",
       "      <th id=\"T_13b6b_level0_col2\" class=\"col_heading level0 col2\" >P3</th>\n",
       "      <th id=\"T_13b6b_level0_col3\" class=\"col_heading level0 col3\" >P3-P1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_13b6b_level0_row0\" class=\"row_heading level0 row0\" >E[R]--Rf</th>\n",
       "      <td id=\"T_13b6b_row0_col0\" class=\"data row0 col0\" >0.033775</td>\n",
       "      <td id=\"T_13b6b_row0_col1\" class=\"data row0 col1\" >0.028160</td>\n",
       "      <td id=\"T_13b6b_row0_col2\" class=\"data row0 col2\" >0.022073</td>\n",
       "      <td id=\"T_13b6b_row0_col3\" class=\"data row0 col3\" >-0.012149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b6b_level0_row1\" class=\"row_heading level0 row1\" >t</th>\n",
       "      <td id=\"T_13b6b_row1_col0\" class=\"data row1 col0\" >2.350435</td>\n",
       "      <td id=\"T_13b6b_row1_col1\" class=\"data row1 col1\" >2.114748</td>\n",
       "      <td id=\"T_13b6b_row1_col2\" class=\"data row1 col2\" >2.008379</td>\n",
       "      <td id=\"T_13b6b_row1_col3\" class=\"data row1 col3\" >-1.235158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b6b_level0_row2\" class=\"row_heading level0 row2\" >Std</th>\n",
       "      <td id=\"T_13b6b_row2_col0\" class=\"data row2 col0\" >0.164469</td>\n",
       "      <td id=\"T_13b6b_row2_col1\" class=\"data row2 col1\" >0.152989</td>\n",
       "      <td id=\"T_13b6b_row2_col2\" class=\"data row2 col2\" >0.127226</td>\n",
       "      <td id=\"T_13b6b_row2_col3\" class=\"data row2 col3\" >0.112578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13b6b_level0_row3\" class=\"row_heading level0 row3\" >SR</th>\n",
       "      <td id=\"T_13b6b_row3_col0\" class=\"data row3 col0\" >1.482894</td>\n",
       "      <td id=\"T_13b6b_row3_col1\" class=\"data row3 col1\" >1.329135</td>\n",
       "      <td id=\"T_13b6b_row3_col2\" class=\"data row3 col2\" >1.252825</td>\n",
       "      <td id=\"T_13b6b_row3_col3\" class=\"data row3 col3\" >-0.779263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c3f2a46ab0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dom_variable in DEPENDENT_VARIABLES_ASSETPRICING[:]:\n",
    "    for is_boom in [-1]:\n",
    "        quantiles = Q  \n",
    "        separate_zero_value=True\n",
    "        df_panel = clean_weekly_panel(reg_panel, is_stablecoin = 0, is_boom = is_boom)\n",
    "        df_panel = df_panel[df_panel[dom_variable]>0]\n",
    "        # Substract risk free rate\n",
    "        df_panel = pd.merge(df_panel,ff3, on='WeekYear')\n",
    "        df_panel['ret_lead_1'] = df_panel['ret_lead_1']-df_panel['RF']\n",
    "        \n",
    "        df_panel = univariate_sort(df_panel, dom_variable, quantiles=quantiles, separate_zero_value=separate_zero_value)\n",
    "        summary_table = univariate_sort_table(df_panel, ret_agg = ret_agg)\n",
    "    \n",
    "        if is_boom == 1:\n",
    "            boom_str = \" boom\"\n",
    "        elif is_boom == 0:\n",
    "            boom_str = \" bust\"\n",
    "        else:\n",
    "            boom_str = \" alltime\"\n",
    "        summary_table = summary_table.style.set_caption(dom_variable+' '+boom_str)\n",
    "        display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "portfolio\n",
       "P3    2784\n",
       "P1    2702\n",
       "P2    2621\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_panel.portfolio.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "portfolio\n",
       "P1    3.509627e+07\n",
       "P2    7.407528e+07\n",
       "P3    2.498114e+08\n",
       "Name: mcap, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_panel.groupby('portfolio')['mcap'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Token', 'Volume', 'Date', 'Inflow_centrality', 'Outflow_centrality',\n",
       "       'TVL', 'volume_in', 'volume_out', 'borrow_rate', 'Supply_share',\n",
       "       'Borrow_share', 'supply_rates', 'betweenness_centrality_volume',\n",
       "       'betweenness_centrality_count', 'vol_in_full_len', 'vol_out_full_len',\n",
       "       'vol_inter_full_len', 'eigen_centrality_undirected',\n",
       "       'total_eigen_centrality_undirected', 'volume_ultimate',\n",
       "       'dollar_exchange_rate', 'stableshare', 'mcap', 'S&P', 'timestamp',\n",
       "       'gas_price_wei', 'ether_price_usd', 'gas_price_usd', 'S&P_log_return_1',\n",
       "       'S&P_log_return_vol_1_30', 'ether_price_usd_log_return_1',\n",
       "       'ether_price_usd_log_return_vol_1_30', 'gas_price_usd_log_return_1',\n",
       "       'gas_price_usd_log_return_vol_1_30', 'Volume_share', 'TVL_share',\n",
       "       'volume_in_share', 'volume_out_share', 'vol_in_full_len_share',\n",
       "       'vol_out_full_len_share', 'vol_inter_full_len_share',\n",
       "       'volume_ultimate_share', 'mcap_share',\n",
       "       'dollar_exchange_rate_log_return_1',\n",
       "       'dollar_exchange_rate_log_return_vol_1_30', 'corr_gas', 'corr_eth',\n",
       "       'corr_sp', 'is_boom'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_panel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assign_zv_portfolio(x, quantiles, prefix=\"P\", separate_zero_value=True):\n",
    "#     # Create an empty result Series with the same index as x.\n",
    "#     result = pd.Series(index=x.index, dtype=object)\n",
    "\n",
    "#     # combine zero values with bottom portfolio\n",
    "#     # Identify rows where the value is 0.\n",
    "#     zero_mask = x == 0\n",
    "#     if zero_mask.sum() == 0:\n",
    "#         result = pd.qcut(\n",
    "#             x,\n",
    "#             q=quantiles,\n",
    "#             labels=[f\"{prefix}{i}\" for i in range(1, len(quantiles))],\n",
    "#         )\n",
    "#     else:\n",
    "#         if separate_zero_value:\n",
    "#             result[zero_mask] = f\"{prefix}0\"\n",
    "#             result[~zero_mask] = pd.qcut(\n",
    "#                 x[~zero_mask],\n",
    "#                 q=quantiles,\n",
    "#                 labels=[f\"{prefix}{i}\" for i in range(1, len(quantiles))],\n",
    "#             )\n",
    "#         else:\n",
    "#             result[zero_mask] = f\"{prefix}1\"\n",
    "#             result[~zero_mask] = pd.qcut(\n",
    "#                 x[~zero_mask],\n",
    "#                 q=quantiles,\n",
    "#                 labels=[f\"{prefix}{i}\" for i in range(1, len(quantiles))],\n",
    "#             )\n",
    "#     return result\n",
    "\n",
    "# def univariate_zv_sort(\n",
    "#     df_panel, dom_variable, quantiles=[0, 0.33, 0.67, 1], separate_zero_value=True\n",
    "# ) -> pd.DataFrame:\n",
    "#     # Assign portfolio for each WeekYear group.\n",
    "#     df_panel[\"portfolio\"] = df_panel.groupby(\"WeekYear\")[dom_variable].transform(\n",
    "#         lambda x: assign_zv_portfolio(\n",
    "#             x, quantiles=quantiles, prefix=\"P\", separate_zero_value=separate_zero_value\n",
    "#         )\n",
    "#     )\n",
    "#     return df_panel\n",
    "# def weighted_average_return(group):\n",
    "#     \"\"\"\n",
    "#     Compute the value-weighted return for a group using the token market capitalization.\n",
    "#     The weighted return is defined as: sum(ret * mcap) / sum(mcap)\n",
    "#     \"\"\"\n",
    "#     return np.average(group[\"ret_lead_1\"], weights=group[\"mcap\"])\n",
    "\n",
    "# def univariate_zv_sort_table(\n",
    "#     df_panel, ret_agg=\"value_weight\", annualized=False\n",
    "# ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Compute the time-series of aggregated portfolio returns for each WeekYear.\n",
    "\n",
    "#     Parameters:\n",
    "#     - ret_agg: choose among \"mean\", \"median\", or \"value_weight\" (for value-weighted returns).\n",
    "#     - annualized: if True, annualize the average return.\n",
    "#     \"\"\"\n",
    "#     if ret_agg == \"mean\":\n",
    "#         portfolio_ts = (\n",
    "#             df_panel.groupby([\"WeekYear\", \"portfolio\"])[\"ret_lead_1\"].mean().unstack()\n",
    "#         )\n",
    "#     elif ret_agg == \"median\":\n",
    "#         portfolio_ts = (\n",
    "#             df_panel.groupby([\"WeekYear\", \"portfolio\"])[\"ret_lead_1\"].median().unstack()\n",
    "#         )\n",
    "#     elif ret_agg == \"value_weight\":\n",
    "#         portfolio_ts = (\n",
    "#             df_panel.groupby([\"WeekYear\", \"portfolio\"])\n",
    "#             .apply(weighted_average_return)\n",
    "#             .unstack()\n",
    "#         )\n",
    "#     else:\n",
    "#         raise ValueError(\"ret_agg must be one of 'mean', 'median', or 'value_weight'\")\n",
    "\n",
    "#     results = {}\n",
    "\n",
    "#     # Loop through each portfolio's time series and compute overall statistics across time.\n",
    "#     for port in portfolio_ts.columns:\n",
    "#         ret_ts = portfolio_ts[port].dropna()  # drop missing values if any\n",
    "#         mean_return = ret_ts.mean()\n",
    "#         std_return = ret_ts.std(ddof=1)\n",
    "#         t_stat, _ = ttest_1samp(ret_ts, popmean=0)\n",
    "#         sharpe = (\n",
    "#             np.sqrt(365 / 7) * mean_return / std_return if std_return != 0 else np.nan\n",
    "#         )\n",
    "\n",
    "#         results[port] = {\n",
    "#             \"E[R]--Rf\": mean_return * 52 if annualized else mean_return,\n",
    "#             \"t\": t_stat,\n",
    "#             \"Std\": std_return,\n",
    "#             \"SR\": sharpe,\n",
    "#         }\n",
    "\n",
    "#     # Determine the number of portfolios (assumes portfolios are labeled like P1, P2, ..., Pn)\n",
    "#     n_quantiles = portfolio_ts.shape[1]\n",
    "\n",
    "#     # Compute the spread portfolio as the time series difference: P{n_quantiles} - P1.\n",
    "#     high_port = portfolio_ts[f\"P{n_quantiles}\"]\n",
    "#     low_port = portfolio_ts[\"P0\"]\n",
    "#     spread_ts = high_port - low_port\n",
    "#     mean_diff = spread_ts.mean()\n",
    "#     std_diff = spread_ts.std(ddof=1)\n",
    "#     t_stat_diff, _ = ttest_1samp(spread_ts.dropna(), popmean=0)\n",
    "#     sharpe_diff = np.sqrt(365 / 7) * mean_diff / std_diff if std_diff != 0 else np.nan\n",
    "\n",
    "#     results[f\"P{n_quantiles}-P0\"] = {\n",
    "#         \"E[R]--Rf\": mean_diff,\n",
    "#         \"t\": t_stat_diff,\n",
    "#         \"Std\": std_diff,\n",
    "#         \"SR\": sharpe_diff,\n",
    "#     }\n",
    "\n",
    "#     summary_table = pd.DataFrame(results)\n",
    "#     return summary_table\n",
    "\n",
    "# for dom_variable in ['betweenness_centrality_volume']:\n",
    "#     for is_boom in [-1]:\n",
    "#         quantiles = [0]\n",
    "#         separate_zero_value=True\n",
    "#         df_panel = clean_weekly_panel(reg_panel, is_stablecoin = 0, is_boom = is_boom)\n",
    "#         # df_panel = df_panel[df_panel[dom_variable]>0]\n",
    "#         df_panel = pd.merge(df_panel,ff3, on='WeekYear')\n",
    "#         df_panel['ret_lead_1'] = df_panel['ret_lead_1']-df_panel['RF']\n",
    "        \n",
    "#         df_panel = univariate_zv_sort(df_panel, dom_variable, quantiles=quantiles, separate_zero_value=separate_zero_value)\n",
    "#         summary_table = univariate_zv_sort_table(df_panel, ret_agg = ret_agg)\n",
    "    \n",
    "#         if is_boom == 1:\n",
    "#             boom_str = \" boom\"\n",
    "#         elif is_boom == 0:\n",
    "#             boom_str = \" bust\"\n",
    "#         else:\n",
    "#             boom_str = \" alltime\"\n",
    "#         summary_table = summary_table.style.set_caption(dom_variable+' '+boom_str)\n",
    "#         display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>WeekYear</th>\n",
       "      <th>ret</th>\n",
       "      <th>volatility</th>\n",
       "      <th>mcap</th>\n",
       "      <th>mcap_share</th>\n",
       "      <th>amihud</th>\n",
       "      <th>is_boom</th>\n",
       "      <th>is_stablecoin</th>\n",
       "      <th>gas_price_usd</th>\n",
       "      <th>...</th>\n",
       "      <th>ret_lead_1</th>\n",
       "      <th>ret_rolling_4</th>\n",
       "      <th>Date</th>\n",
       "      <th>MKT</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RF</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "      <th>portfolio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$AKC</td>\n",
       "      <td>2022-13</td>\n",
       "      <td>2.837605</td>\n",
       "      <td>74.413035</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.759577e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.331418</td>\n",
       "      <td>2.981673</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>-0.0415</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>13</td>\n",
       "      <td>2022</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$AKC</td>\n",
       "      <td>2022-14</td>\n",
       "      <td>-0.331388</td>\n",
       "      <td>1.283833</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.154088e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202849</td>\n",
       "      <td>1.662195</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>-0.0192</td>\n",
       "      <td>-0.0330</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>14</td>\n",
       "      <td>2022</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$AKC</td>\n",
       "      <td>2022-15</td>\n",
       "      <td>-0.202819</td>\n",
       "      <td>0.920389</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.229143e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372408</td>\n",
       "      <td>1.122250</td>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>-0.0172</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>15</td>\n",
       "      <td>2022</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$AKC</td>\n",
       "      <td>2022-16</td>\n",
       "      <td>-0.372378</td>\n",
       "      <td>0.445062</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.675409e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.435399</td>\n",
       "      <td>0.283776</td>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>16</td>\n",
       "      <td>2022</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$AKC</td>\n",
       "      <td>2022-17</td>\n",
       "      <td>-0.435369</td>\n",
       "      <td>0.771352</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.528750e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.468173</td>\n",
       "      <td>-0.811116</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>-0.0335</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>17</td>\n",
       "      <td>2022</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8102</th>\n",
       "      <td>⚗️</td>\n",
       "      <td>2021-45</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>0.570483</td>\n",
       "      <td>1.079282e+08</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>2.533261e-08</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368249</td>\n",
       "      <td>-0.250154</td>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>45</td>\n",
       "      <td>2021</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8103</th>\n",
       "      <td>⚗️</td>\n",
       "      <td>2021-46</td>\n",
       "      <td>-0.368239</td>\n",
       "      <td>0.848700</td>\n",
       "      <td>8.796850e+07</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>5.236743e-08</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017683</td>\n",
       "      <td>-0.503924</td>\n",
       "      <td>2021-11-19</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0176</td>\n",
       "      <td>-0.0160</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>46</td>\n",
       "      <td>2021</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>⚗️</td>\n",
       "      <td>2021-47</td>\n",
       "      <td>-0.017673</td>\n",
       "      <td>0.547065</td>\n",
       "      <td>6.951797e+07</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>5.845556e-08</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140675</td>\n",
       "      <td>-0.403373</td>\n",
       "      <td>2021-11-26</td>\n",
       "      <td>-0.0256</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>47</td>\n",
       "      <td>2021</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8105</th>\n",
       "      <td>⚗️</td>\n",
       "      <td>2021-48</td>\n",
       "      <td>-0.140665</td>\n",
       "      <td>0.539667</td>\n",
       "      <td>6.975927e+07</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>5.331698e-08</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092045</td>\n",
       "      <td>-0.478920</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>-0.0168</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>48</td>\n",
       "      <td>2021</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8106</th>\n",
       "      <td>⚗️</td>\n",
       "      <td>2021-9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247073</td>\n",
       "      <td>-0.097285</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8107 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token WeekYear       ret  volatility          mcap  mcap_share  \\\n",
       "0     $AKC  2022-13  2.837605   74.413035  0.000000e+00    0.000000   \n",
       "1     $AKC  2022-14 -0.331388    1.283833  0.000000e+00    0.000000   \n",
       "2     $AKC  2022-15 -0.202819    0.920389  0.000000e+00    0.000000   \n",
       "3     $AKC  2022-16 -0.372378    0.445062  0.000000e+00    0.000000   \n",
       "4     $AKC  2022-17 -0.435369    0.771352  0.000000e+00    0.000000   \n",
       "...    ...      ...       ...         ...           ...         ...   \n",
       "8102    ⚗️  2021-45 -0.022914    0.570483  1.079282e+08    0.000119   \n",
       "8103    ⚗️  2021-46 -0.368239    0.848700  8.796850e+07    0.000103   \n",
       "8104    ⚗️  2021-47 -0.017673    0.547065  6.951797e+07    0.000082   \n",
       "8105    ⚗️  2021-48 -0.140665    0.539667  6.975927e+07    0.000080   \n",
       "8106    ⚗️   2021-9  0.000000         NaN  0.000000e+00    0.000000   \n",
       "\n",
       "            amihud  is_boom  is_stablecoin  gas_price_usd  ...  ret_lead_1  \\\n",
       "0     2.759577e-07    False              0       0.000209  ...   -0.331418   \n",
       "1     2.154088e-07    False              0       0.000212  ...   -0.202849   \n",
       "2     2.229143e-07    False              0       0.000138  ...   -0.372408   \n",
       "3     1.675409e-07    False              0       0.000153  ...   -0.435399   \n",
       "4     5.528750e-07    False              0       0.000327  ...   -0.468173   \n",
       "...            ...      ...            ...            ...  ...         ...   \n",
       "8102  2.533261e-08    False              0       0.000714  ...   -0.368249   \n",
       "8103  5.236743e-08    False              0       0.000580  ...   -0.017683   \n",
       "8104  5.845556e-08    False              0       0.000560  ...   -0.140675   \n",
       "8105  5.331698e-08    False              0       0.000575  ...   -0.092045   \n",
       "8106           NaN     True              0       0.000194  ...   -0.247073   \n",
       "\n",
       "      ret_rolling_4        Date     MKT     SMB     HML       RF  Week  Year  \\\n",
       "0          2.981673  2022-04-01  0.0015  0.0101 -0.0415  0.00003    13  2022   \n",
       "1          1.662195  2022-04-08 -0.0192 -0.0330  0.0220  0.00003    14  2022   \n",
       "2          1.122250  2022-04-14 -0.0172  0.0178  0.0224  0.00003    15  2022   \n",
       "3          0.283776  2022-04-22 -0.0323 -0.0039  0.0232  0.00003    16  2022   \n",
       "4         -0.811116  2022-04-29 -0.0335 -0.0026  0.0054  0.00003    17  2022   \n",
       "...             ...         ...     ...     ...     ...      ...   ...   ...   \n",
       "8102      -0.250154  2021-11-12 -0.0026 -0.0053  0.0083  0.00001    45  2021   \n",
       "8103      -0.503924  2021-11-19 -0.0014 -0.0176 -0.0160  0.00001    46  2021   \n",
       "8104      -0.403373  2021-11-26 -0.0256 -0.0226  0.0263  0.00001    47  2021   \n",
       "8105      -0.478920  2021-12-03 -0.0218 -0.0168  0.0145  0.00002    48  2021   \n",
       "8106      -0.097285  2021-03-05  0.0008 -0.0145  0.0762  0.00001     9  2021   \n",
       "\n",
       "      portfolio  \n",
       "0            P1  \n",
       "1            P1  \n",
       "2            P2  \n",
       "3            P1  \n",
       "4            P1  \n",
       "...         ...  \n",
       "8102         P2  \n",
       "8103         P2  \n",
       "8104         P1  \n",
       "8105         P1  \n",
       "8106         P2  \n",
       "\n",
       "[8107 rows x 37 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3c1a7\">\n",
       "  <caption>volume_ultimate_share alltime</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >primary_portfolio</th>\n",
       "      <th id=\"T_3c1a7_level0_col0\" class=\"col_heading level0 col0\" >P1</th>\n",
       "      <th id=\"T_3c1a7_level0_col1\" class=\"col_heading level0 col1\" >P2</th>\n",
       "      <th id=\"T_3c1a7_level0_col2\" class=\"col_heading level0 col2\" >P3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >secondary_portfolio</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3c1a7_level0_row0\" class=\"row_heading level0 row0\" >Q1</th>\n",
       "      <td id=\"T_3c1a7_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_3c1a7_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "      <td id=\"T_3c1a7_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c1a7_level0_row1\" class=\"row_heading level0 row1\" >Q2</th>\n",
       "      <td id=\"T_3c1a7_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_3c1a7_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "      <td id=\"T_3c1a7_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c1a7_level0_row2\" class=\"row_heading level0 row2\" >Q3</th>\n",
       "      <td id=\"T_3c1a7_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_3c1a7_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_3c1a7_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c3f2a46ab0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for secondary_variable in ['mcap']:\n",
    "    for dom_variable in DEPENDENT_VARIABLES_ASSETPRICING[:]:\n",
    "        for is_boom in [-1]:\n",
    "            quantiles = Q\n",
    "            secondary_quantiles=[0,0.3,0.7,1]\n",
    "            seprarate_zero_value=True\n",
    "            df_panel = clean_weekly_panel(reg_panel, is_stablecoin = 0, is_boom = is_boom)\n",
    "            df_panel = df_panel[df_panel[dom_variable]>0]\n",
    "            df_panel = pd.merge(df_panel,ff3, on='WeekYear')\n",
    "            df_panel= double_sort(df_panel, dom_variable, secondary_variable=secondary_variable, quantiles=quantiles, secondary_quantiles=secondary_quantiles, separate_zero_value=separate_zero_value)\n",
    "            summary_table = double_sort_table(df_panel, ret_agg=ret_agg)\n",
    "            if is_boom == 1:\n",
    "                boom_str = \" boom\"\n",
    "            elif is_boom == 0:\n",
    "                boom_str = \" bust\"\n",
    "            else:\n",
    "                boom_str = \"alltime\"\n",
    "            summary_table = summary_table.style.set_caption(dom_variable +' '+ boom_str)\n",
    "            display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalIndex(['P1', 'P2', 'P3'], categories=['P1', 'P2', 'P3'], ordered=True, dtype='category', name='primary_portfolio')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Results for volume_ultimate_share | Model: CMKT+CMOM+CSIZE \n",
      "                 P1       P2        P3     CDOM\n",
      "alpha      0.0341**  0.0260*   0.0239*  -0.0109\n",
      "alpha_t      (1.99)   (1.91)    (1.94)  (-1.05)\n",
      "CMKT        -0.1259  -0.1499   -0.0338   0.0906\n",
      "CMKT_t      (-0.83)  (-0.80)   (-0.30)   (0.91)\n",
      "CMOM         0.1784   0.3778    0.2221   0.0567\n",
      "CMOM_t       (0.94)   (1.57)    (1.49)   (0.49)\n",
      "CSIZE       -0.1244  -0.1982  -0.3445*  -0.2165\n",
      "CSIZE_t     (-0.63)  (-0.67)   (-1.75)  (-1.60)\n",
      "R-squared     0.014    0.046     0.047    0.023\n",
      "N               131      132       134      131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "factor_models = [\"MKT\", \"CMKT\", \"CMKT+CMOM+CSIZE\"]\n",
    "is_boom = -1\n",
    "\n",
    "for factor_model in factor_models[2:3]:\n",
    "    for dom_variable in DEPENDENT_VARIABLES_ASSETPRICING[:2]:\n",
    "        for is_boom in [-1]:\n",
    "            # 1. Prepare your data\n",
    "            quantiles = Q #[0,0.2,0.4,0.6,0.8,1] #[0, 0.33, 0.66, 1] \n",
    "            separate_zero_value = False\n",
    "            df_panel = clean_weekly_panel(reg_panel, is_stablecoin=0, is_boom=is_boom)\n",
    "            df_panel = df_panel[df_panel[dom_variable] > 0]\n",
    "\n",
    "            df_panel = univariate_sort(\n",
    "                df_panel, dom_variable, quantiles, separate_zero_value=separate_zero_value\n",
    "            )\n",
    "            dominance_portfolios = get_dominance_portfolios(df_panel, ret_agg=ret_agg)\n",
    "            dominance_portfolios.rename(columns={dominance_portfolios.columns[-1]: \"CDOM\"}, inplace=True)\n",
    "            portfolios = list(dominance_portfolios.columns)\n",
    "\n",
    "            # 2. Merge all factors into a single DataFrame\n",
    "            factors_data = pd.merge(dominance_portfolios, ff3, on=[\"WeekYear\"], how=\"left\")\n",
    "            factors_data = pd.merge(factors_data, ltw3, on=[\"WeekYear\"], how=\"left\")\n",
    "            for p in portfolios:\n",
    "                factors_data[p] = factors_data[p]-factors_data['RF']\n",
    "            # 3. Build a list of factor names from the formula (plus \"alpha\")\n",
    "            #    Example: factor_model=\"MKT + SMB + HML\" => [\"MKT\", \"SMB\", \"HML\"]\n",
    "            #    We'll store \"alpha\" and then each factor, plus a matching \"_t\" row for t-stats\n",
    "            raw_factors = factor_model.replace(\" \", \"\").split(\"+\")\n",
    "            factor_names = [\"alpha\"] + raw_factors  # \"alpha\" is the renamed Intercept\n",
    "            row_list = []\n",
    "            for f in factor_names:\n",
    "                row_list.append(f)      # e.g. \"alpha\", \"MKT\", \"SMB\", ...\n",
    "                row_list.append(f\"{f}_t\")  # e.g. \"alpha_t\", \"MKT_t\", ...\n",
    "\n",
    "            # Finally, add R-squared and N at the bottom\n",
    "            row_list += [\"R-squared\", \"N\"]\n",
    "            final_table = pd.DataFrame(index=row_list, columns=portfolios)\n",
    "\n",
    "            # 4. Run a separate regression for each portfolio\n",
    "            for p in portfolios:\n",
    "                formula = f\"{p} ~ {factor_model}\"\n",
    "\n",
    "                # Use Newey–West (HAC) standard errors\n",
    "                model = smf.ols(formula=formula, data=factors_data).fit(\n",
    "                    cov_type=\"HAC\", cov_kwds={\"maxlags\": 4}\n",
    "                )\n",
    "\n",
    "                # Extract estimates, t-stats, p-values\n",
    "                coefs = model.params.copy()\n",
    "                tvals = model.tvalues.copy()\n",
    "                pvals = model.pvalues.copy()\n",
    "\n",
    "                # Rename \"Intercept\" to \"alpha\"\n",
    "                if \"Intercept\" in coefs.index:\n",
    "                    coefs.rename({\"Intercept\": \"alpha\"}, inplace=True)\n",
    "                    tvals.rename({\"Intercept\": \"alpha\"}, inplace=True)\n",
    "                    pvals.rename({\"Intercept\": \"alpha\"}, inplace=True)\n",
    "\n",
    "                # Fill each factor row with the coefficient and the next row with the t-stat\n",
    "                for f in factor_names:\n",
    "                    if f in coefs.index:\n",
    "                        star = significance_stars(pvals[f])\n",
    "                        \n",
    "                        # Row for coefficient (with stars)\n",
    "                        final_table.loc[f, p] = f\"{coefs[f]:.4f}{star}\"\n",
    "\n",
    "                        # Row for p-value\n",
    "                        # final_table.loc[\"p\", p] = f\"({pvals[f]:.2f})\"\n",
    "                        \n",
    "                        # Row for t-stat\n",
    "                        final_table.loc[f\"{f}_t\", p] = f\"({tvals[f]:.2f})\"\n",
    "                    else:\n",
    "                        # If factor not found in the regression, fill with blanks or zeros\n",
    "                        final_table.loc[f, p] = \"\"\n",
    "                        final_table.loc[f\"{f}_t\", p] = \"\"\n",
    "\n",
    "                # Fill in R-squared and # obs\n",
    "                final_table.loc[\"R-squared\", p] = f\"{model.rsquared:.3f}\"\n",
    "                final_table.loc[\"N\", p]         = f\"{int(model.nobs)}\"\n",
    "\n",
    "            # 5. Print or export the final table\n",
    "            print(f\"== Results for {dom_variable} | Model: {factor_model} \")\n",
    "            print(final_table)\n",
    "            # final_table.to_latex('panelA.tex', index=True, header=False, column_format='lrrrr', \n",
    "            # bold_rows=True).replace('\\\\toprule\\n', '').replace('\\\\bottomrule\\n', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAMA MCBETH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Factor  Risk Premium  \\emph{t}\n",
      "0       CDOM        -0.253    -1.629\n",
      "1       CMKT         1.175     5.724\n",
      "2       CMOM         0.084     0.686\n",
      "3      CSIZE         0.384     3.150\n",
      "4  Intercept         7.602     3.751\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script to render the table of Fama Macbeth.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "from environ.constants import (\n",
    "    ALL_NAMING_DICT,\n",
    "    DEPENDENT_VARIABLES_ASSETPRICING,\n",
    "    PROCESSED_DATA_PATH,\n",
    "    TABLE_PATH,\n",
    ")\n",
    "from environ.process.asset_pricing.assetpricing_functions import (\n",
    "    clean_weekly_panel,\n",
    "    univariate_sort,\n",
    "    get_dominance_portfolios,\n",
    "    reg_fama_macbeth,\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # compute means for portfolio returns (can change to median)\n",
    "    ret_agg = \"value_weight\"\n",
    "    is_boom = -1\n",
    "    # load the regression panel dataset\n",
    "    reg_panel = pd.read_pickle(\n",
    "        PROCESSED_DATA_PATH / \"panel_main.pickle.zip\", compression=\"zip\"\n",
    "    )\n",
    "    # load factors\n",
    "    ff3 = pd.read_csv(PROCESSED_DATA_PATH / \"FF3.csv\")\n",
    "    ltw3 = pd.read_csv(PROCESSED_DATA_PATH / \"LTW3.csv\")\n",
    "    for dom_variable in DEPENDENT_VARIABLES_ASSETPRICING[:1]:\n",
    "        quantiles = Q\n",
    "        separate_zero_value = False \n",
    "        df_panel = clean_weekly_panel(reg_panel, is_stablecoin=0, is_boom=is_boom)\n",
    "        df_panel = df_panel[df_panel[dom_variable] > 0]\n",
    "        df_panel = univariate_sort(\n",
    "            df_panel, dom_variable, quantiles, separate_zero_value=separate_zero_value\n",
    "        )\n",
    "        dominance_factor = get_dominance_portfolios(df_panel)\n",
    "        dominance_factor.rename(\n",
    "            columns={dominance_factor.columns[-1]: \"CDOM\"}, inplace=True\n",
    "        )\n",
    "        # Get the test assets\n",
    "        assets_panel = clean_weekly_panel(reg_panel, is_stablecoin=0, is_boom=-1)\n",
    "\n",
    "        # Calculate the mean market cap for each token\n",
    "        mean_market_cap = assets_panel.groupby('Token')['mcap'].mean()\n",
    "\n",
    "        # Identify tokens with an average market cap above 1 million\n",
    "        tokens_above_1m = mean_market_cap[mean_market_cap > 1e6].index\n",
    "\n",
    "        # Filter the original DataFrame to keep only these tokens\n",
    "        assets_panel = assets_panel[assets_panel['Token'].isin(tokens_above_1m)]\n",
    "\n",
    "        # Merge all factors\n",
    "        data_fama_macbeth = pd.merge(dominance_factor, ff3, on=[\"WeekYear\"], how=\"left\")\n",
    "        data_fama_macbeth = pd.merge(\n",
    "            data_fama_macbeth, ltw3, on=[\"WeekYear\"], how=\"left\"\n",
    "        )\n",
    "        # Merge factors with returns\n",
    "        data_fama_macbeth = pd.merge(\n",
    "            data_fama_macbeth, assets_panel, on=[\"WeekYear\"], how=\"left\"\n",
    "        )\n",
    "        data_fama_macbeth = data_fama_macbeth.dropna()\n",
    "\n",
    "        # Run the Fama–MacBeth regression\n",
    "        data_fama_macbeth[\"excess_ret\"] = (\n",
    "            data_fama_macbeth[\"ret\"] - data_fama_macbeth[\"RF\"]\n",
    "        )\n",
    "        fama_macbeth_results = reg_fama_macbeth(\n",
    "            data_fama_macbeth, formula=\"excess_ret ~ CMKT + CMOM + CSIZE + CDOM\"\n",
    "        )\n",
    "        fama_macbeth_results = fama_macbeth_results.round(3)\n",
    "        fama_macbeth_results.drop(\"t_stat\", axis=1, inplace=True)\n",
    "        fama_macbeth_results.rename(\n",
    "            columns={\"factor\":\"Factor\", \"risk_premium\":\"Risk Premium\", \"t_stat_NW\":r\"\\emph{t}\"}, inplace=True\n",
    "        )\n",
    "        print(fama_macbeth_results)\n",
    "        # file_name = (\n",
    "        #     TABLE_PATH / \"assetpricing\" / f\"assetpricing_famamacbeth_{dom_variable}\"\n",
    "        # )\n",
    "\n",
    "        # fama_macbeth_results.to_latex(\n",
    "        #     f\"{file_name}.tex\",\n",
    "        #     index=True,\n",
    "        #     escape=False,\n",
    "        # )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel regression for returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_weekly_betweenness(reg_panel):\n",
    "#     # add supply rates\n",
    "#     reg_panel[\"daily_supply_return\"] = reg_panel[\"supply_rates\"] / 365.2425\n",
    "#     reg_panel.sort_values(by=[\"Token\", \"Date\"], ascending=True, inplace=True)\n",
    "\n",
    "#     # calculate daily returns\n",
    "\n",
    "#     reg_panel[\"ret\"] = reg_panel.groupby(\"Token\")[\"dollar_exchange_rate\"].pct_change(\n",
    "#         fill_method=None\n",
    "#     )\n",
    "#     reg_panel[\"ret\"] = (1+reg_panel[\"ret\"]) * (1+reg_panel[\"daily_supply_return\"]) - 1\n",
    "#     # compute amihud illiquidity measure\n",
    "#     reg_panel[\"amihud\"] = np.where(\n",
    "#         reg_panel[\"Volume\"] == 0, np.nan, reg_panel[\"ret\"].abs() / reg_panel[\"Volume\"]\n",
    "#     )\n",
    "#     reg_panel[\"is_stablecoin\"] = (\n",
    "#         reg_panel.groupby(\"Token\")[\"stableshare\"].transform(\"max\") > 0\n",
    "#     ).astype(int)\n",
    "\n",
    "#     # Add columns for the week and year\n",
    "#     reg_panel[\"Week\"] = reg_panel[\"Date\"].dt.isocalendar().week.replace(53, 52)\n",
    "#     reg_panel[\"Year\"] = reg_panel[\"Date\"].dt.isocalendar().year\n",
    "#     reg_panel[\"WeekYear\"] = (\n",
    "#         reg_panel[\"Year\"].astype(str) + \"-\" + reg_panel[\"Week\"].astype(str)\n",
    "#     )\n",
    "\n",
    "#     agg_dict = {\n",
    "#         \"ret\": (\"ret\", lambda x: (1 + x).prod() - 1),\n",
    "#         \"mcap\": (\"mcap\", \"mean\"),\n",
    "#         \"amihud\": (\"amihud\", \"mean\"),\n",
    "#         \"is_boom\": (\"is_boom\", \"last\"),\n",
    "#         \"is_stablecoin\": (\"is_stablecoin\", \"last\"),\n",
    "#         \"gas_price_usd\": (\"gas_price_usd\", \"mean\"),\n",
    "#         \"stableshare\": (\"stableshare\", \"mean\"),\n",
    "#         \"gas_price_usd_log_return_vol_1_30\": (\"gas_price_usd_log_return_vol_1_30\", \"mean\"),\n",
    "#         \"ether_price_usd_log_return_vol_1_30\": (\"ether_price_usd_log_return_vol_1_30\", \"mean\"),\n",
    "#         \"Supply_share\": (\"Supply_share\", \"mean\"),\n",
    "#         \"supply_rates\": (\"supply_rates\", \"mean\"),\n",
    "#     }\n",
    "#     for col in DEPENDENT_VARIABLES:\n",
    "#         agg_dict[col] = (col, \"mean\")\n",
    "\n",
    "#     reg_panel = reg_panel.groupby([\"Token\", \"WeekYear\"]).agg(**agg_dict).reset_index()\n",
    "\n",
    "#     # Ensure the DataFrame is sorted by Token and WeekYear\n",
    "#     reg_panel = reg_panel.sort_values([\"Token\", \"WeekYear\"])\n",
    "\n",
    "#     # Create the lead returns, i.e. returns one week ahead\n",
    "#     reg_panel[\"ret_lead_1\"] = reg_panel.groupby(\"Token\")[\"ret\"].shift(-1)\n",
    "#     reg_panel = reg_panel.dropna(subset=[\"ret_lead_1\"])\n",
    "\n",
    "#     #Winsorize\n",
    "#     # reg_panel[\"ret_lead_1\"] = reg_panel.groupby([\"WeekYear\"])[\"ret_lead_1\"].transform(\n",
    "#     #     lambda x: x.clip(lower=x.quantile(0.005), upper=x.quantile(0.995))\n",
    "#     # )\n",
    "#     return reg_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_daily_betweenness(reg_panel):\n",
    "#     # add supply rates\n",
    "#     reg_panel[\"daily_supply_return\"] = reg_panel[\"supply_rates\"] / 365.2425\n",
    "#     reg_panel.sort_values(by=[\"Token\", \"Date\"], ascending=True, inplace=True)\n",
    "\n",
    "#     # calculate daily returns\n",
    "\n",
    "#     reg_panel[\"ret\"] = reg_panel.groupby(\"Token\")[\"dollar_exchange_rate\"].pct_change(\n",
    "#         fill_method=None\n",
    "#     )\n",
    "#     reg_panel[\"ret\"] = (1+reg_panel[\"ret\"]) * (1+reg_panel[\"daily_supply_return\"]) - 1\n",
    "#     # compute amihud illiquidity measure\n",
    "#     reg_panel[\"amihud\"] = np.where(\n",
    "#         reg_panel[\"Volume\"] == 0, np.nan, reg_panel[\"ret\"].abs() / reg_panel[\"Volume\"]\n",
    "#     )\n",
    "#     reg_panel[\"is_stablecoin\"] = (\n",
    "#         reg_panel.groupby(\"Token\")[\"stableshare\"].transform(\"max\") > 0\n",
    "#     ).astype(int)\n",
    "\n",
    "#     agg_dict = {\n",
    "#         \"ret\": (\"ret\", lambda x: (1 + x).prod() - 1),\n",
    "#         \"is_boom\": (\"is_boom\", \"last\"),\n",
    "#         \"is_stablecoin\": (\"is_stablecoin\", \"last\"),\n",
    "#     }\n",
    "#     for col in DEPENDENT_VARIABLES + [\"mcap\", \"amihud\", \"stableshare\", \"gas_price_usd\",\"gas_price_usd_log_return_vol_1_30\", \"ether_price_usd_log_return_vol_1_30\"]:\n",
    "#         agg_dict[col] = (col, \"mean\")\n",
    "\n",
    "#     reg_panel = reg_panel.groupby([\"Token\", \"Date\"]).agg(**agg_dict).reset_index()\n",
    "\n",
    "#     # Ensure the DataFrame is sorted by Token and WeekYear\n",
    "#     reg_panel = reg_panel.sort_values([\"Token\", \"Date\"])\n",
    "\n",
    "#     # Create the lead returns, i.e. returns one week ahead\n",
    "#     reg_panel[\"ret_lead_1\"] = reg_panel.groupby(\"Token\")[\"ret\"].shift(-1)\n",
    "#     reg_panel = reg_panel.dropna(subset=[\"ret_lead_1\"])\n",
    "\n",
    "#     #Winsorize\n",
    "#     # reg_panel[\"ret_lead_1\"] = reg_panel.groupby([\"WeekYear\"])[\"ret_lead_1\"].transform(\n",
    "#     #     lambda x: x.clip(lower=x.quantile(0.005), upper=x.quantile(0.995))\n",
    "#     # )\n",
    "#     return reg_panel\n",
    "\n",
    "# # reg_panel['is_stable'] = (reg_panel.groupby('Token')['stableshare'].transform('max') > 0).astype(int)\n",
    "# # reg_panel = reg_panel.sort_values([\"Token\", \"Date\"])\n",
    "# # reg_panel[\"ret\"] = reg_panel.groupby(\"Token\")[\"dollar_exchange_rate\"].pct_change(\n",
    "# # fill_method=None\n",
    "# # )\n",
    "# # reg_panel[\"log_mcap\"] = np.log(reg_panel[\"mcap\"])\n",
    "# from linearmodels.panel import PanelOLS\n",
    "# stablecoins_list = [\"DAI\", \"USDC\", \"USDT\", \"FEI\", \"FRAX\", \"PAX\"]\n",
    "# df_panel = clean_daily_betweenness(reg_panel)\n",
    "# df_panel = df_panel[df_panel[\"Token\"].isin(stablecoins_list)]\n",
    "# df_panel = df_panel.groupby(\"Token\").filter(\n",
    "#     lambda group: group[\"betweenness_centrality_volume\"].max() > 0\n",
    "# )\n",
    "# df_panel = df_panel[(df_panel['mcap'] > 0)]\n",
    "# df_panel['log_mcap'] = np.log(df_panel['mcap'])\n",
    "\n",
    "# # Set a multi-index with the security identifier and date.\n",
    "# df_panel = df_panel.set_index(['Token', 'Date'])\n",
    "# model = PanelOLS.from_formula(\n",
    "#     \"ret_lead_1 ~ betweenness_centrality_volume + log_mcap + stableshare + is_boom +gas_price_usd_log_return_vol_1_30+ gas_price_usd\",\n",
    "#     data=df_panel,\n",
    "# )\n",
    "\n",
    "# results = model.fit()\n",
    "# print(results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Token', 'Volume', 'Date', 'Inflow_centrality', 'Outflow_centrality',\n",
       "       'TVL', 'volume_in', 'volume_out', 'borrow_rate', 'Supply_share',\n",
       "       'Borrow_share', 'supply_rates', 'betweenness_centrality_volume',\n",
       "       'betweenness_centrality_count', 'vol_in_full_len', 'vol_out_full_len',\n",
       "       'vol_inter_full_len', 'eigen_centrality_undirected',\n",
       "       'total_eigen_centrality_undirected', 'volume_ultimate',\n",
       "       'dollar_exchange_rate', 'stableshare', 'mcap', 'S&P', 'timestamp',\n",
       "       'gas_price_wei', 'ether_price_usd', 'gas_price_usd', 'S&P_log_return_1',\n",
       "       'S&P_log_return_vol_1_30', 'ether_price_usd_log_return_1',\n",
       "       'ether_price_usd_log_return_vol_1_30', 'gas_price_usd_log_return_1',\n",
       "       'gas_price_usd_log_return_vol_1_30', 'Volume_share', 'TVL_share',\n",
       "       'volume_in_share', 'volume_out_share', 'vol_in_full_len_share',\n",
       "       'vol_out_full_len_share', 'vol_inter_full_len_share',\n",
       "       'volume_ultimate_share', 'mcap_share',\n",
       "       'dollar_exchange_rate_log_return_1',\n",
       "       'dollar_exchange_rate_log_return_vol_1_30', 'corr_gas', 'corr_eth',\n",
       "       'corr_sp', 'is_boom'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_panel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_monthly_panel(reg_panel, is_stablecoin=0, is_boom=-1):\n",
    "\n",
    "#     # Filter for stablecoins\n",
    "#     if is_stablecoin == 1:\n",
    "#         reg_panel = reg_panel[reg_panel[\"stableshare\"] > 0]\n",
    "#     elif is_stablecoin == 0:\n",
    "#         reg_panel = reg_panel[reg_panel[\"stableshare\"] == 0]\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "#     ## Filter out tokens that existed for less than 2 months\n",
    "#     # reg_panel = reg_panel[\n",
    "#     #     reg_panel[\"Token\"].map(reg_panel[\"Token\"].value_counts()) >= 60\n",
    "#     # ]\n",
    "\n",
    "#     ## Filter out tokens with low peak market capitalization\n",
    "#     # reg_panel = reg_panel.groupby(\"Token\").filter(\n",
    "#     #     lambda group: group[\"mcap\"].max() >= 50e6\n",
    "#     # )\n",
    "\n",
    "#     # Add supply rates\n",
    "#     reg_panel[\"daily_supply_return\"] = reg_panel[\"supply_rates\"] / 365.2425\n",
    "#     reg_panel.sort_values(by=[\"Token\", \"Date\"], ascending=True, inplace=True)\n",
    "\n",
    "#     # Calculate daily returns\n",
    "#     reg_panel[\"ret\"] = reg_panel.groupby(\"Token\")[\"dollar_exchange_rate\"].pct_change(\n",
    "#         fill_method=None\n",
    "#     )\n",
    "\n",
    "#     # Compute Amihud illiquidity measure\n",
    "#     reg_panel[\"amihud\"] = np.where(\n",
    "#         reg_panel[\"Volume\"] == 0, np.nan, reg_panel[\"ret\"].abs() / reg_panel[\"Volume\"]\n",
    "#     )\n",
    "#     reg_panel[\"is_stablecoin\"] = (\n",
    "#         reg_panel.groupby(\"Token\")[\"stableshare\"].transform(\"max\") > 0\n",
    "#     ).astype(int)\n",
    "\n",
    "#     # Instead of week, extract month and year for monthly aggregation\n",
    "#     reg_panel[\"Month\"] = reg_panel[\"Date\"].dt.month\n",
    "#     reg_panel[\"Year\"] = reg_panel[\"Date\"].dt.year\n",
    "#     reg_panel[\"YearMonth\"] = reg_panel[\"Year\"].astype(str) + \"-\" + reg_panel[\"Month\"].astype(str)\n",
    "\n",
    "#     # Define the aggregation dictionary, unchanged except grouping key is now YearMonth\n",
    "#     agg_dict = {\n",
    "#         \"ret\": (\"ret\", lambda x: (1 + x).prod() - 1),\n",
    "#         \"mcap\": (\"mcap\", \"mean\"),\n",
    "#         \"mcap_share\": (\"mcap_share\", \"mean\"),\n",
    "#         \"amihud\": (\"amihud\", \"mean\"),\n",
    "#         \"is_boom\": (\"is_boom\", \"last\"),\n",
    "#         \"is_stablecoin\": (\"is_stablecoin\", \"last\"),\n",
    "#         \"gas_price_usd\": (\"gas_price_usd\", \"mean\"),\n",
    "#         \"stableshare\": (\"stableshare\", \"mean\"),\n",
    "#         \"gas_price_usd_log_return_vol_1_30\": (\n",
    "#             \"gas_price_usd_log_return_vol_1_30\",\n",
    "#             \"mean\",\n",
    "#         ),\n",
    "#         \"ether_price_usd_log_return_1\": (\"ether_price_usd_log_return_1\", \"mean\"),\n",
    "#         \"ether_price_usd_log_return_vol_1_30\": (\n",
    "#             \"ether_price_usd_log_return_vol_1_30\",\n",
    "#             \"mean\",\n",
    "#         ),\n",
    "#         \"S&P_log_return_vol_1_30\": (\"S&P_log_return_vol_1_30\", \"mean\"),\n",
    "#         \"Supply_share\": (\"Supply_share\", \"mean\"),\n",
    "#         \"supply_rates\": (\"supply_rates\", \"mean\"),\n",
    "#     }\n",
    "#     for col in DEPENDENT_VARIABLES:\n",
    "#         agg_dict[col] = (col, \"mean\")\n",
    "\n",
    "#     # Group by Token and YearMonth for monthly panel\n",
    "#     reg_panel = reg_panel.groupby([\"Token\", \"YearMonth\"]).agg(**agg_dict).reset_index()\n",
    "\n",
    "#     # Ensure the DataFrame is sorted by Token and YearMonth\n",
    "#     reg_panel = reg_panel.sort_values([\"Token\", \"YearMonth\"])\n",
    "\n",
    "#     # Winsorize returns by YearMonth to reduce the impact of extreme values\n",
    "#     reg_panel[\"ret\"] = reg_panel.groupby([\"YearMonth\"])[\"ret\"].transform(\n",
    "#         lambda x: x.clip(lower=x.quantile(0.01), upper=x.quantile(0.99))\n",
    "#     )\n",
    "\n",
    "#     # Create lead returns (i.e., one month ahead)\n",
    "#     reg_panel[\"ret_lead_1\"] = reg_panel.groupby(\"Token\")[\"ret\"].shift(-1)\n",
    "#     reg_panel = reg_panel.dropna(subset=[\"ret_lead_1\"])\n",
    "\n",
    "#     # Compute rolling 4-month returns (including current month)\n",
    "#     # For a given month, ret_rolling_4 = (1+ret[t-3])*(1+ret[t-2])*(1+ret[t-1])*(1+ret[t]) - 1\n",
    "#     reg_panel[\"ret_rolling_4\"] = reg_panel.groupby(\"Token\")[\"ret\"].transform(\n",
    "#         lambda x: (1 + x).rolling(window=4, min_periods=1).apply(np.prod, raw=True) - 1\n",
    "#     )\n",
    "\n",
    "#     # Boom and bust filtering needs to be done at the end, to prevent wrong shifting in returns\n",
    "#     if is_boom == 1:\n",
    "#         reg_panel = reg_panel[reg_panel[\"is_boom\"] == 1]\n",
    "#     elif is_boom == 0:\n",
    "#         reg_panel = reg_panel[reg_panel[\"is_boom\"] == 0]\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "#     return reg_panel\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from linearmodels.panel import PanelOLS\n",
    "\n",
    "# # -------------------------------\n",
    "# # 1. Data Cleaning and Preparation\n",
    "# # -------------------------------\n",
    "# # (Uncomment or adjust the following lines as needed)\n",
    "# # reg_panel['is_stable'] = (reg_panel.groupby('Token')['stableshare'].transform('max') > 0).astype(int)\n",
    "# # reg_panel = reg_panel.sort_values([\"Token\", \"Date\"])\n",
    "# # reg_panel[\"ret\"] = reg_panel.groupby(\"Token\")[\"dollar_exchange_rate\"].pct_change(fill_method=None)\n",
    "# # reg_panel[\"log_mcap\"] = np.log(reg_panel[\"mcap\"])\n",
    "\n",
    "# # Clean your panel data using your helper function\n",
    "# df_panel = clean_monthly_panel(reg_panel, is_stablecoin=-1, is_boom=-1)\n",
    "\n",
    "# df_panel = df_panel.rename(columns={'S&P_log_return_vol_1_30': 'SP_vol'})\n",
    "# # (Optional) filter for a specific list of tokens:\n",
    "# # stablecoins_list = [\"DAI\", \"USDC\", \"USDT\", \"FEI\", \"FRAX\", \"PAX\"]\n",
    "# # df_panel = df_panel[df_panel[\"Token\"].isin(stablecoins_list)]\n",
    "\n",
    "# # (Optional) you can filter tokens based on stableshare here if needed\n",
    "# # df_panel = df_panel.groupby(\"Token\").filter(lambda group: group[\"stableshare\"].max() == 0)\n",
    "\n",
    "# # Keep observations with positive market cap and create log_mcap\n",
    "# df_panel = df_panel[(df_panel['mcap'] > 0)].copy()\n",
    "# df_panel['log_mcap'] = np.log(df_panel['mcap'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Create a date variable from 'WeekYear' and set a multi-index with [Token, YearWeekDay]\n",
    "# df_panel['YearMonth'] = pd.to_datetime(df_panel['YearMonth'], format='%Y-%M')\n",
    "# df_panel = df_panel.set_index(['Token', 'YearMonth'])\n",
    "\n",
    "# # -------------------------------\n",
    "# # 2. Define Regression Specifications\n",
    "# # -------------------------------\n",
    "# # Note: We use \"TimeEffects\" and \"EntityEffects\" as markers in the formula.\n",
    "# # Later, we will replace them with C(YearWeekDay) and C(Token) respectively.\n",
    "# dom_variable = \"eigen_centrality_undirected\"  # Change this to your desired variable\n",
    "# all_reg_specs = [\n",
    "#     \"ret_lead_1 ~ {dom_variable} + log_mcap + is_stablecoin\",\n",
    "#     \"ret_lead_1 ~ {dom_variable} + log_mcap + gas_price_usd + is_stablecoin + ether_price_usd_log_return_1\",\n",
    "#     \"ret_lead_1 ~ {dom_variable} + log_mcap + gas_price_usd + is_stablecoin + ret + ret_rolling_4\",\n",
    "#     \"ret_lead_1 ~ {dom_variable} + log_mcap + gas_price_usd + is_stablecoin + supply_rates + is_boom\",\n",
    "#     \"ret_lead_1 ~ {dom_variable} + log_mcap + gas_price_usd + is_stablecoin + supply_rates + is_boom:{dom_variable}\",\n",
    "#     \"ret_lead_1 ~ {dom_variable} + log_mcap + gas_price_usd + is_stablecoin + ether_price_usd_log_return_1 + supply_rates + is_boom + ret + ret_rolling_4\",\n",
    "#     \"ret_lead_1 ~ {dom_variable} + log_mcap + gas_price_usd + is_stablecoin + TimeEffects + ret + ret_rolling_4\",\n",
    "#     \"ret_lead_1 ~ {dom_variable} + log_mcap + gas_price_usd + TimeEffects + EntityEffects + ret + ret_rolling_4\"\n",
    "# ]\n",
    "\n",
    "# # -------------------------------\n",
    "# # 3. Run Regressions and Collect Results\n",
    "# # -------------------------------\n",
    "# reg_results = []\n",
    "\n",
    "# for spec in all_reg_specs:\n",
    "#     # Determine if the specification contains Time and/or Entity effects\n",
    "#     has_time = \"TimeEffects\" in spec\n",
    "#     has_entity = \"EntityEffects\" in spec\n",
    "\n",
    "#     if has_time and has_entity:\n",
    "#         spec_label = \"Entity & Time FE\"\n",
    "#     elif has_time:\n",
    "#         spec_label = \"Time FE\"\n",
    "#     elif has_entity:\n",
    "#         spec_label = \"Entity FE\"\n",
    "#     else:\n",
    "#         spec_label = \"No FE\"\n",
    "\n",
    "#     model = PanelOLS.from_formula(spec, data=df_panel)\n",
    "#     results = model.fit()\n",
    "\n",
    "#     # Store the fitted results along with the fixed effect flags\n",
    "#     reg_results.append({\n",
    "#         \"spec_label\": spec_label,\n",
    "#         \"results\": results,\n",
    "#         \"has_time\": has_time,\n",
    "#         \"has_entity\": has_entity\n",
    "#     })\n",
    "\n",
    "# def produce_latex_table(reg_results, \n",
    "#                         table_caption=\"OLS Regression Results\",\n",
    "#                         table_label=\"tab:ols_results\"):\n",
    "#     \"\"\"\n",
    "#     Produce a LaTeX-formatted table string from a list of regression results.\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     reg_results : list of dict\n",
    "#         Each element should be a dictionary with:\n",
    "#           - \"spec_label\": a string describing the specification (e.g., \"Time FE\")\n",
    "#           - \"results\": the fitted PanelOLSResults object\n",
    "#           - \"has_time\": boolean, True if Time Fixed Effects are used.\n",
    "#           - \"has_entity\": boolean, True if Entity Fixed Effects are used.\n",
    "#     table_caption : str\n",
    "#         The caption for the LaTeX table.\n",
    "#     table_label : str\n",
    "#         The label used for referencing the LaTeX table.\n",
    "        \n",
    "#     Returns\n",
    "#     -------\n",
    "#     latex_str : str\n",
    "#         A string containing LaTeX code for the regression table.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Gather all variable names that appear in any regression\n",
    "#     all_vars = set()\n",
    "#     for item in reg_results:\n",
    "#         for var in item[\"results\"].params.index:\n",
    "#             # Skip intercept if you don't want it in the table\n",
    "#             # if var.lower() in [\"intercept\", \"const\"]:\n",
    "#             #     continue\n",
    "#             all_vars.add(var)\n",
    "#     all_vars = list(all_vars)\n",
    "    \n",
    "#     # Helper function to assign significance stars based on p-value thresholds\n",
    "#     def significance_stars(p):\n",
    "#         if p < 0.01:\n",
    "#             return \"***\"\n",
    "#         elif p < 0.05:\n",
    "#             return \"**\"\n",
    "#         elif p < 0.10:\n",
    "#             return \"*\"\n",
    "#         else:\n",
    "#             return \"\"\n",
    "    \n",
    "#     n_regs = len(reg_results)\n",
    "    \n",
    "#     lines = []\n",
    "#     lines.append(r\"\\begin{table}[ht]\")\n",
    "#     lines.append(r\"\\centering\")\n",
    "#     lines.append(fr\"\\caption{{{table_caption}}}\")\n",
    "#     lines.append(fr\"\\label{{{table_label}}}\")\n",
    "#     lines.append(r\"\\begin{tabular}{l\" + \"c\" * n_regs + \"}\")\n",
    "#     lines.append(r\"\\toprule\")\n",
    "    \n",
    "#     # Column headers: (1), (2), (3), etc.\n",
    "#     col_header = \" & \" + \" & \".join([f\"({i+1})\" for i in range(n_regs)]) + r\" \\\\\"\n",
    "#     lines.append(col_header)\n",
    "#     lines.append(r\"\\midrule\")\n",
    "    \n",
    "#     # For each variable, add a row for coefficients and a row for t-statistics.\n",
    "#     # Replace underscores in variable names with spaces.\n",
    "#     for var in all_vars:\n",
    "#         var_label = var.replace('_', ' ')\n",
    "#         coef_row = [var_label]\n",
    "#         tstat_row = [\"\"]\n",
    "        \n",
    "#         for item in reg_results:\n",
    "#             res = item[\"results\"]\n",
    "#             if var in res.params.index:\n",
    "#                 coef_val = res.params[var]\n",
    "#                 p_val    = res.pvalues[var]\n",
    "#                 t_stat   = res.tstats[var]\n",
    "                \n",
    "#                 star_str = significance_stars(p_val)\n",
    "#                 coef_str = f\"{coef_val:.2f}{star_str}\"\n",
    "#                 t_str    = f\"[{t_stat:.2f}]\"\n",
    "#             else:\n",
    "#                 coef_str = \"\"\n",
    "#                 t_str    = \"\"\n",
    "            \n",
    "#             coef_row.append(coef_str)\n",
    "#             tstat_row.append(t_str)\n",
    "        \n",
    "#         lines.append(\" & \".join(coef_row) + r\" \\\\\")\n",
    "#         lines.append(\" & \".join(tstat_row) + r\" \\\\\")\n",
    "    \n",
    "#     # Additional regression statistics: R-squared row\n",
    "#     r2_row = [\"R-squared\"]\n",
    "#     for item in reg_results:\n",
    "#         r2_val = item[\"results\"].rsquared\n",
    "#         r2_row.append(f\"{r2_val:.3f}\")\n",
    "#     lines.append(\" & \".join(r2_row) + r\" \\\\\")\n",
    "    \n",
    "#     # Observations row\n",
    "#     nobs_row = [\"Observations\"]\n",
    "#     for item in reg_results:\n",
    "#         nobs_val = item[\"results\"].nobs\n",
    "#         nobs_row.append(f\"{nobs_val:d}\")\n",
    "#     lines.append(\" & \".join(nobs_row) + r\" \\\\\")\n",
    "    \n",
    "#     # --- Modified Fixed Effects Rows ---\n",
    "#     # Entity Fixed Effects row\n",
    "#     entity_fe_row = [\"Entity FE\"]\n",
    "#     # Time Fixed Effects row\n",
    "#     time_fe_row   = [\"Time FE\"]\n",
    "    \n",
    "#     for item in reg_results:\n",
    "#         entity_fe_value = \"YES\" if item.get(\"has_entity\") else \"NO\"\n",
    "#         time_fe_value   = \"YES\" if item.get(\"has_time\") else \"NO\"\n",
    "#         entity_fe_row.append(entity_fe_value)\n",
    "#         time_fe_row.append(time_fe_value)\n",
    "    \n",
    "#     lines.append(\" & \".join(entity_fe_row) + r\" \\\\\")\n",
    "#     lines.append(\" & \".join(time_fe_row) + r\" \\\\\")\n",
    "    \n",
    "#     lines.append(r\"\\bottomrule\")\n",
    "#     lines.append(r\"\\end{tabular}\")\n",
    "#     lines.append(r\"\\end{table}\")\n",
    "    \n",
    "#     return \"\\n\".join(lines)\n",
    "\n",
    "# # Generate and print the LaTeX table code\n",
    "# table_code = produce_latex_table(reg_results)\n",
    "# print(table_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\caption{OLS Regression Results}\n",
      "\\label{tab:ols_results}\n",
      "\\begin{tabular}{lccccccccc}\n",
      "\\toprule\n",
      " & (1) & (2) & (3) & (4) & (5) & (6) & (7) & (8) & (9) \\\\\n",
      "\\midrule\n",
      "log mcap & -0.00 & -0.00 & -0.00 & -0.00 & -0.00 & -0.00 & -0.00 & -0.00 & -0.00 \\\\\n",
      " & [-0.64] & [-0.53] & [-1.00] & [-0.86] & [-1.05] & [-0.52] & [-0.64] & [-0.69] & [-0.62] \\\\\n",
      "volatility & -0.02 & -0.02 & 0.06 & 0.05 & 0.06 & -0.03 & -0.03 & -0.02 & -0.03 \\\\\n",
      " & [-0.40] & [-0.35] & [0.97] & [0.90] & [1.02] & [-0.47] & [-0.49] & [-0.39] & [-0.52] \\\\\n",
      "$\\Delta$ eigen centrality undirected &  & 0.36*** &  &  &  &  &  &  &  \\\\\n",
      " &  & [12.40] &  &  &  &  &  &  &  \\\\\n",
      "$\\Delta$ total eigen centrality undirected &  &  &  &  &  & 0.41*** &  &  &  \\\\\n",
      " &  &  &  &  &  & [13.40] &  &  &  \\\\\n",
      "is boom & -0.03 & -0.04 & -0.02 & -0.02 & -0.03 & -0.04 & -0.02 & -0.02 & -0.02 \\\\\n",
      " & [-0.80] & [-1.12] & [-0.52] & [-0.57] & [-0.58] & [-0.95] & [-0.56] & [-0.55] & [-0.58] \\\\\n",
      "$\\Delta$ volume out share &  &  &  &  &  &  &  &  & 0.49*** \\\\\n",
      " &  &  &  &  &  &  &  &  & [15.18] \\\\\n",
      "$\\Delta$ vol inter full len share &  &  & 0.10*** &  &  &  &  &  &  \\\\\n",
      " &  &  & [6.04] &  &  &  &  &  &  \\\\\n",
      "is stablecoin & -0.01 & -0.00 & 0.02 & 0.02 & 0.02 & -0.01 & -0.01 & -0.01 & -0.01 \\\\\n",
      " & [-0.14] & [-0.06] & [0.34] & [0.35] & [0.39] & [-0.12] & [-0.21] & [-0.14] & [-0.25] \\\\\n",
      "$\\Delta$ betweenness centrality count &  &  &  &  & 0.11*** &  &  &  &  \\\\\n",
      " &  &  &  &  & [5.37] &  &  &  &  \\\\\n",
      "$\\Delta$ betweenness centrality volume &  &  &  & 0.09*** &  &  &  &  &  \\\\\n",
      " &  &  &  & [6.13] &  &  &  &  &  \\\\\n",
      "$\\Delta$ volume in share &  &  &  &  &  &  &  & 0.44*** &  \\\\\n",
      " &  &  &  &  &  &  &  & [13.89] &  \\\\\n",
      "$\\Delta$ Volume share &  &  &  &  &  &  & 0.47*** &  &  \\\\\n",
      " &  &  &  &  &  &  & [14.70] &  &  \\\\\n",
      "gas price usd & 326.09*** & 326.86*** & 278.47** & 246.93** & 288.09** & 314.17*** & 310.61*** & 309.01*** & 313.44*** \\\\\n",
      " & [2.85] & [2.80] & [2.24] & [1.98] & [2.31] & [2.73] & [2.74] & [2.70] & [2.79] \\\\\n",
      "$\\Delta$ volume ultimate share & 0.41*** &  &  &  &  &  &  &  &  \\\\\n",
      " & [13.95] &  &  &  &  &  &  &  &  \\\\\n",
      "R-squared & 0.195 & 0.162 & 0.051 & 0.052 & 0.043 & 0.183 & 0.211 & 0.194 & 0.222 \\\\\n",
      "Observations & 854 & 854 & 854 & 854 & 854 & 854 & 854 & 854 & 854 \\\\\n",
      "Entity FE & NO & NO & NO & NO & NO & NO & NO & NO & NO \\\\\n",
      "Time FE & NO & NO & NO & NO & NO & NO & NO & NO & NO \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# 0. Imports\n",
    "# ---------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from linearmodels.panel import PanelOLS\n",
    "\n",
    "# ---------------------------------\n",
    "# 1. Data prep\n",
    "# ---------------------------------\n",
    "dom_variable = \"betweenness_centrality_volume\"   # default; loop will override\n",
    "\n",
    "# Clean your panel data using your helper function\n",
    "df_panel = clean_weekly_panel(reg_panel, is_stablecoin=-1, is_boom=-1)\n",
    "df_panel = df_panel[df_panel[dom_variable] > 0]\n",
    "df_panel = df_panel.rename(columns={'S&P_log_return_vol_1_30': 'SP_vol'})\n",
    "\n",
    "# (Optional) filter for a specific list of tokens:\n",
    "# stablecoins_list = [\"DAI\", \"USDC\", \"USDT\", \"FEI\", \"FRAX\", \"PAX\"]\n",
    "# df_panel = df_panel[df_panel[\"Token\"].isin(stablecoins_list)]\n",
    "\n",
    "# (Optional) filter tokens on stableshare\n",
    "# df_panel = df_panel.groupby(\"Token\").filter(lambda g: g[\"stableshare\"].max() == 0)\n",
    "\n",
    "# Keep observations with positive market cap and create log_mcap\n",
    "df_panel = df_panel[df_panel[\"mcap\"] > 0].copy()\n",
    "df_panel[\"log_mcap\"] = np.log(df_panel[\"mcap\"])\n",
    "\n",
    "# Construct Δ-log-change columns for every dependent variable\n",
    "for dom_variable in DEPENDENT_VARIABLES:\n",
    "    df_panel[f\"{dom_variable}_logchange\"] = (\n",
    "        np.log(df_panel[dom_variable]) - np.log(df_panel[dom_variable].shift(1))\n",
    "    )\n",
    "\n",
    "# TVL log-change (specific example that doesn’t sit in DEPENDENT_VARIABLES)\n",
    "df_panel[\"tvl_logchange\"] = np.log(df_panel[\"TVL\"]) - np.log(df_panel[\"TVL\"].shift(1))\n",
    "\n",
    "# Indexing\n",
    "df_panel[\"YearWeekDay\"] = pd.to_datetime(df_panel[\"WeekYear\"] + \"-1\", format=\"%Y-%W-%w\")\n",
    "df_panel = df_panel.set_index([\"Token\", \"YearWeekDay\"])\n",
    "df_panel = df_panel.dropna(subset=[\"ret_lead_1\"])\n",
    "\n",
    "# ---------------------------------\n",
    "# 2. Regression specs\n",
    "# ---------------------------------\n",
    "all_reg_specs = []\n",
    "for dom_variable in DEPENDENT_VARIABLES:\n",
    "    indepvar = f\"{dom_variable}_logchange\"\n",
    "    all_reg_specs.append(\n",
    "        f\"tvl_logchange ~ {indepvar} + log_mcap + is_stablecoin + gas_price_usd + is_boom + volatility\"\n",
    "    )\n",
    "\n",
    "# ---------------------------------\n",
    "# 3. Run regressions\n",
    "# ---------------------------------\n",
    "reg_results = []\n",
    "\n",
    "for spec in all_reg_specs:\n",
    "    has_time   = \"TimeEffects\"   in spec\n",
    "    has_entity = \"EntityEffects\" in spec\n",
    "\n",
    "    spec_label = (\n",
    "        \"Entity & Time FE\" if (has_time and has_entity)\n",
    "        else \"Time FE\"     if has_time\n",
    "        else \"Entity FE\"   if has_entity\n",
    "        else \"No FE\"\n",
    "    )\n",
    "\n",
    "    model   = PanelOLS.from_formula(spec, data=df_panel)\n",
    "    results = model.fit()\n",
    "\n",
    "    reg_results.append(\n",
    "        {\n",
    "            \"spec_label\": spec_label,\n",
    "            \"results\": results,\n",
    "            \"has_time\": has_time,\n",
    "            \"has_entity\": has_entity,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# ---------------------------------\n",
    "# 4. Helpers for LaTeX output\n",
    "# ---------------------------------\n",
    "def _latex_friendly_name(var_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Turn an internal regression variable name into a LaTeX-ready label.\n",
    "\n",
    "    • Any variable that ends with '_logchange' becomes\n",
    "      '$\\\\Delta$ <pretty base name>'.\n",
    "    • Otherwise, underscores are simply replaced by spaces.\n",
    "    \"\"\"\n",
    "    if var_name.endswith(\"_logchange\"):\n",
    "        base = var_name[:-10]                   # drop '_logchange'\n",
    "        return r\"$\\Delta$ \" + base.replace(\"_\", \" \")\n",
    "    else:\n",
    "        return var_name.replace(\"_\", \" \")\n",
    "\n",
    "\n",
    "def produce_latex_table(\n",
    "    reg_results,\n",
    "    table_caption=\"TVL change on dominance change\",\n",
    "    table_label=\"tab:ols_results\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a LaTeX table from a list of PanelOLS regression results.\n",
    "    All *_logchange regressors are printed as 'Δ <variable>'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Collect every parameter name that appears in any model\n",
    "    all_vars = set()\n",
    "    for item in reg_results:\n",
    "        all_vars.update(item[\"results\"].params.index)\n",
    "    all_vars = list(all_vars)\n",
    "\n",
    "    # Significance symbols\n",
    "    def stars(p):\n",
    "        return \"***\" if p < 0.01 else \"**\" if p < 0.05 else \"*\" if p < 0.10 else \"\"\n",
    "\n",
    "    n_regs = len(reg_results)\n",
    "    lines = []\n",
    "    lines.append(r\"\\begin{table}[ht]\")\n",
    "    lines.append(r\"\\centering\")\n",
    "    lines.append(fr\"\\caption{{{table_caption}}}\")\n",
    "    lines.append(fr\"\\label{{{table_label}}}\")\n",
    "    lines.append(r\"\\begin{tabular}{l\" + \"c\" * n_regs + \"}\")\n",
    "    lines.append(r\"\\toprule\")\n",
    "    lines.append(\" & \" + \" & \".join(f\"({i+1})\" for i in range(n_regs)) + r\" \\\\\")\n",
    "    lines.append(r\"\\midrule\")\n",
    "\n",
    "    # Coefficients and t-statistics\n",
    "    for var in all_vars:\n",
    "        pretty = _latex_friendly_name(var)\n",
    "        coef_row, t_row = [pretty], [\"\"]\n",
    "\n",
    "        for item in reg_results:\n",
    "            res = item[\"results\"]\n",
    "            if var in res.params.index:\n",
    "                coef = res.params[var]\n",
    "                pval = res.pvalues[var]\n",
    "                tval = res.tstats[var]\n",
    "                coef_row.append(f\"{coef:.2f}{stars(pval)}\")\n",
    "                t_row.append(f\"[{tval:.2f}]\")\n",
    "            else:\n",
    "                coef_row.append(\"\")\n",
    "                t_row.append(\"\")\n",
    "\n",
    "        lines.append(\" & \".join(coef_row) + r\" \\\\\")\n",
    "        lines.append(\" & \".join(t_row)   + r\" \\\\\")\n",
    "\n",
    "    # Additional statistics\n",
    "    r2_row   = [\"R-squared\"]    + [f\"{x['results'].rsquared:.3f}\" for x in reg_results]\n",
    "    nobs_row = [\"Observations\"] + [f\"{x['results'].nobs:d}\"      for x in reg_results]\n",
    "    ent_row  = [\"Entity FE\"]    + [\"YES\" if x[\"has_entity\"] else \"NO\" for x in reg_results]\n",
    "    time_row = [\"Time FE\"]      + [\"YES\" if x[\"has_time\"]   else \"NO\" for x in reg_results]\n",
    "\n",
    "    for row in (r2_row, nobs_row, ent_row, time_row):\n",
    "        lines.append(\" & \".join(row) + r\" \\\\\")\n",
    "\n",
    "    lines.append(r\"\\bottomrule\")\n",
    "    lines.append(r\"\\end{tabular}\")\n",
    "    lines.append(r\"\\end{table}\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# 5. Generate & display table code\n",
    "# ---------------------------------\n",
    "table_code = produce_latex_table(reg_results)\n",
    "print(table_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

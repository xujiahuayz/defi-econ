{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to render the asset pricing table\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import ttest_1samp\n",
    "from regtabletotext import prettify_result\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from environ.constants import (\n",
    "    DEPENDENT_VARIABLES,\n",
    "    PROCESSED_DATA_PATH,\n",
    "    STABLE_DICT,\n",
    "    TABLE_PATH,\n",
    ")\n",
    "from environ.process.asset_pricing.assetpricing_functions import reg_fama_macbeth, clean_weekly_panel, univariate_sort, double_sort \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load factors\n",
    "ff3 = pd.read_csv(PROCESSED_DATA_PATH/\"FF3.csv\") \n",
    "ltw3 = pd.read_csv(PROCESSED_DATA_PATH/\"LTW3.csv\")\n",
    "\n",
    "# load the regression panel dataset\n",
    "reg_panel = pd.read_pickle(\n",
    "    PROCESSED_DATA_PATH / \"panel_main.pickle.zip\", compression=\"zip\"\n",
    ")\n",
    "\n",
    "# stable non-stable info dict\n",
    "stable_nonstable_info = {\n",
    "    \"stablecoin\": reg_panel[reg_panel[\"Token\"].isin(STABLE_DICT.keys())],\n",
    "    \"non-stablecoin\": reg_panel[~reg_panel[\"Token\"].isin(STABLE_DICT.keys())],\n",
    "    \"all\": reg_panel,\n",
    "}\n",
    "\n",
    "# How are returns aggregated for each portfolio\n",
    "ret_agg = 'mean'\n",
    "\n",
    "DEPENDENT_VARIABLES_bis = ['volume_ultimate_share']\n",
    "# ,'eigen_centrality_undirected','total_eigen_centrality_undirected','Volume_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv(PROCESSED_DATA_PATH/'CRSP_data.csv')\n",
    "\n",
    "# Calculate market capitalization as the absolute price times shares outstanding\n",
    "stocks['mcap'] = stocks['prc'].abs() * stocks['shrout']\n",
    "stocks = stocks.rename({\"vol\":\"Volume\"}, axis='columns')\n",
    "stocks['Week'] = stocks['date'].dt.isocalendar().week.replace(53,52)\n",
    "stocks['Year'] = stocks['date'].dt.isocalendar().year\n",
    "stocks['WeekYear'] = stocks['Year'].astype(str) + '-' +  stocks['Week'].astype(str)\n",
    "\n",
    "stocks = (\n",
    "    stocks\n",
    "    .groupby(['permno', 'WeekYear'])\n",
    "    .agg(\n",
    "        ret=('ret', lambda x: (1 + x).prod() - 1),\n",
    "        Volume=('Volume', 'sum'),\n",
    "        mcap = ('mcap', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "stocks['ret'] = stocks.groupby(['WeekYear'])['ret'].transform(\n",
    "        lambda x: x.clip(lower=x.quantile(0.01), upper=x.quantile(0.99))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiko = pd.read_csv(PROCESSED_DATA_PATH/'kaiko_alltokens.csv')\n",
    "# kaiko.rename({'market_cap':'mcap', 'volume':'vol_shares'}, axis='columns', inplace=True)\n",
    "# kaiko['date'] = pd.to_datetime(kaiko['timestamp'], unit='ms')\n",
    "# kaiko['Week'] = kaiko['date'].dt.isocalendar().week.replace(53,52)\n",
    "# kaiko['Year'] = kaiko['date'].dt.isocalendar().year\n",
    "# # kaiko = kaiko.dropna(subset=['Volume','mcap'])\n",
    "# kaiko = kaiko[kaiko.date >= \"2020-07-01\"]\n",
    "# kaiko['WeekYear'] = kaiko['Year'].astype(str) + '-' +  kaiko['Week'].astype(str)\n",
    "# kaiko['ret'] = kaiko.groupby('token')['close'].pct_change()\n",
    "# kaiko['Volume'] = kaiko['vol_shares'] * kaiko['close']\n",
    "# kaiko['amihud'] = kaiko['ret'].abs() / kaiko['Volume']\n",
    "\n",
    "# kaiko = (\n",
    "#     kaiko\n",
    "#     .groupby(['token', 'WeekYear'])\n",
    "#     .agg(\n",
    "#         ret=('ret', lambda x: (1 + x).prod() - 1),\n",
    "#         Volume=('Volume', 'sum'),\n",
    "#         mcap = ('mcap', 'mean'),\n",
    "#         amihud = ('amihud', 'mean')\n",
    "#     )\n",
    "#     .reset_index()\n",
    "# )\n",
    "# # kaiko = kaiko[kaiko.mcap >= 1e6]\n",
    "\n",
    "# kaiko['ret'] = kaiko.groupby(['WeekYear'])['ret'].transform(\n",
    "#         lambda x: x.clip(lower=x.quantile(0.01), upper=x.quantile(0.99))\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P5-P1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-0.008854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t-Stat</th>\n",
       "      <td>4.751849</td>\n",
       "      <td>3.862016</td>\n",
       "      <td>2.200547</td>\n",
       "      <td>2.065947</td>\n",
       "      <td>-0.300227</td>\n",
       "      <td>-2.433307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StdDev</th>\n",
       "      <td>0.138323</td>\n",
       "      <td>0.166640</td>\n",
       "      <td>0.157193</td>\n",
       "      <td>0.154141</td>\n",
       "      <td>0.145295</td>\n",
       "      <td>0.055780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe</th>\n",
       "      <td>0.508133</td>\n",
       "      <td>0.419707</td>\n",
       "      <td>0.239417</td>\n",
       "      <td>0.224518</td>\n",
       "      <td>-0.032225</td>\n",
       "      <td>-1.146200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              P1        P2        P3        P4        P5     P5-P1\n",
       "Mean    0.009734  0.009686  0.005212  0.004793 -0.000648 -0.008854\n",
       "t-Stat  4.751849  3.862016  2.200547  2.065947 -0.300227 -2.433307\n",
       "StdDev  0.138323  0.166640  0.157193  0.154141  0.145295  0.055780\n",
       "Sharpe  0.508133  0.419707  0.239417  0.224518 -0.032225 -1.146200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dom_variable = 'amihud'\n",
    "n_quantiles = 5\n",
    "df_panel = kaiko\n",
    "summary_table = univariate_sort(df_panel,dom_variable, n_quantiles, ret_agg = ret_agg)\n",
    "\n",
    "# Compute the difference: H minus L\n",
    "pivot = df_panel.pivot_table(index='WeekYear', columns='portfolio', values='ret')\n",
    "diff_returns = pivot[f'P{n_quantiles}'] - pivot['P1']\n",
    "mean_diff = diff_returns.mean() if ret_agg == 'mean' else diff_returns.median()\n",
    "std_diff = diff_returns.std(ddof=1)\n",
    "t_stat_diff, p_value_diff = ttest_1samp(diff_returns, popmean=0)\n",
    "\n",
    "summary_table[f'P{n_quantiles}-P1'] = {\n",
    "    'Mean': mean_diff,\n",
    "    't-Stat': t_stat_diff,\n",
    "    # 'p-value': p_value_diff,\n",
    "    'StdDev': std_diff,\n",
    "    'Sharpe':  np.sqrt(365/7) * mean_diff / std_diff\n",
    "}\n",
    "\n",
    "display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "portfolio\n",
       "P1    1.648888e+08\n",
       "P2    2.302142e+08\n",
       "P3    3.121709e+08\n",
       "P4    1.050085e+09\n",
       "P5    7.304891e+09\n",
       "Name: mcap, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaiko.groupby('portfolio')['mcap'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asset pricing factor tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>primary_portfolio</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secondary_portfolio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>-0.010356</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.055668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>-0.009321</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.012742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>-0.007058</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>0.013985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "primary_portfolio          P1        P2        P3\n",
       "secondary_portfolio                              \n",
       "Q1                  -0.010356  0.012103  0.055668\n",
       "Q2                  -0.009321  0.007156  0.012742\n",
       "Q3                  -0.007058 -0.001811  0.013985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_panel = kaiko.groupby('WeekYear').filter(lambda group: group['mcap'].count() >= 20)\n",
    "n_quantiles = 3\n",
    "summary_table = double_sort(df_panel,dom_variable, secondary_variable='mcap', n_quantiles=n_quantiles, ret_agg=ret_agg)\n",
    "display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Model:\n",
      "CDOM ~ CMKT\n",
      "\n",
      "Coefficients:\n",
      "           Estimate  Std. Error  t-Statistic  p-Value\n",
      "Intercept     0.142       0.003       41.591    0.000\n",
      "CMKT          0.126       0.037        3.417    0.001\n",
      "\n",
      "Summary statistics:\n",
      "- Number of observations: 6,298\n",
      "- R-squared: 0.002, Adjusted R-squared: 0.002\n",
      "- F-statistic: 11.677 on 1 and 6296 DF, p-value: 0.001\n",
      "\n",
      "OLS Model:\n",
      "CDOM ~ CMKT + CMOM + CSIZE\n",
      "\n",
      "Coefficients:\n",
      "           Estimate  Std. Error  t-Statistic  p-Value\n",
      "Intercept     0.134       0.004       37.264      0.0\n",
      "CMKT          0.132       0.037        3.565      0.0\n",
      "CMOM          0.248       0.051        4.903      0.0\n",
      "CSIZE         0.238       0.052        4.559      0.0\n",
      "\n",
      "Summary statistics:\n",
      "- Number of observations: 6,298\n",
      "- R-squared: 0.009, Adjusted R-squared: 0.009\n",
      "- F-statistic: 19.339 on 3 and 6294 DF, p-value: 0.000\n",
      "\n",
      "CSIZE factor is long small cap and short large cap\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "for dom_variable in DEPENDENT_VARIABLES_bis:\n",
    "    for is_boom in [-1]:\n",
    "        n_quantiles = 3\n",
    "        df_panel = clean_weekly_panel(reg_panel, dom_variable, is_stablecoin = 0, is_boom = is_boom)\n",
    "        summary_table = univariate_sort(df_panel,dom_variable, n_quantiles)\n",
    "\n",
    "        # Compute the difference: H minus L\n",
    "        pivot = df_panel.pivot_table(index='WeekYear', columns='portfolio', values='ret')\n",
    "        pivot[\"CDOM\"] = pivot[f\"P{n_quantiles}\"] - pivot['P1']\n",
    "        dominance_factor = pivot[[\"CDOM\"]].reset_index()\n",
    "        assets_panel = clean_weekly_panel(reg_panel, dom_variable, is_stablecoin = 0, is_boom = -1)\n",
    "        # merge all factors\n",
    "        factors_data = pd.merge(dominance_factor, ff3, on=[\"WeekYear\"], how=\"left\")\n",
    "        factors_data = pd.merge(factors_data, ltw3, on=[\"WeekYear\"], how=\"left\")\n",
    "        # merge factors with returns\n",
    "        factors_data = pd.merge(factors_data, assets_panel, on=[\"WeekYear\"], how=\"left\")\n",
    "        factors_data = factors_data.dropna()\n",
    "        # AP_test_ff3 = smf.ols(formula= 'CDOM ~ MKT + SMB + HML', data=factors_data).fit()\n",
    "        # prettify_result(AP_test_ff3)\n",
    "        AP_test_cmkt = smf.ols(formula= 'CDOM ~ CMKT', data=factors_data).fit()\n",
    "        prettify_result(AP_test_cmkt)\n",
    "        AP_test_ltw3 = smf.ols(formula= 'CDOM ~ CMKT + CMOM + CSIZE', data=factors_data).fit()\n",
    "        prettify_result(AP_test_ltw3)\n",
    "        print(\"CSIZE factor is long small cap and short large cap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAMA MCBETH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_254fb\">\n",
       "  <caption>volume_ultimate_share alltime</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_254fb_level0_col0\" class=\"col_heading level0 col0\" >factor</th>\n",
       "      <th id=\"T_254fb_level0_col1\" class=\"col_heading level0 col1\" >risk_premium</th>\n",
       "      <th id=\"T_254fb_level0_col2\" class=\"col_heading level0 col2\" >t_stat</th>\n",
       "      <th id=\"T_254fb_level0_col3\" class=\"col_heading level0 col3\" >t_stat_NW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_254fb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_254fb_row0_col0\" class=\"data row0 col0\" >CDOM</td>\n",
       "      <td id=\"T_254fb_row0_col1\" class=\"data row0 col1\" >1.639000</td>\n",
       "      <td id=\"T_254fb_row0_col2\" class=\"data row0 col2\" >2.413000</td>\n",
       "      <td id=\"T_254fb_row0_col3\" class=\"data row0 col3\" >2.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_254fb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_254fb_row1_col0\" class=\"data row1 col0\" >CMKT</td>\n",
       "      <td id=\"T_254fb_row1_col1\" class=\"data row1 col1\" >1.064000</td>\n",
       "      <td id=\"T_254fb_row1_col2\" class=\"data row1 col2\" >5.167000</td>\n",
       "      <td id=\"T_254fb_row1_col3\" class=\"data row1 col3\" >5.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_254fb_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_254fb_row2_col0\" class=\"data row2 col0\" >CMOM</td>\n",
       "      <td id=\"T_254fb_row2_col1\" class=\"data row2 col1\" >0.069000</td>\n",
       "      <td id=\"T_254fb_row2_col2\" class=\"data row2 col2\" >0.649000</td>\n",
       "      <td id=\"T_254fb_row2_col3\" class=\"data row2 col3\" >0.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_254fb_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_254fb_row3_col0\" class=\"data row3 col0\" >CSIZE</td>\n",
       "      <td id=\"T_254fb_row3_col1\" class=\"data row3 col1\" >0.363000</td>\n",
       "      <td id=\"T_254fb_row3_col2\" class=\"data row3 col2\" >3.205000</td>\n",
       "      <td id=\"T_254fb_row3_col3\" class=\"data row3 col3\" >3.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_254fb_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_254fb_row4_col0\" class=\"data row4 col0\" >Intercept</td>\n",
       "      <td id=\"T_254fb_row4_col1\" class=\"data row4 col1\" >6.180000</td>\n",
       "      <td id=\"T_254fb_row4_col2\" class=\"data row4 col2\" >4.243000</td>\n",
       "      <td id=\"T_254fb_row4_col3\" class=\"data row4 col3\" >3.470000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ec2fed09b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dom_variable in DEPENDENT_VARIABLES_bis:\n",
    "    for is_boom in [-1]:\n",
    "        n_quantiles = 3\n",
    "        df_panel = clean_weekly_panel(reg_panel, dom_variable, is_stablecoin = 0, is_boom = is_boom)\n",
    "        summary_table = univariate_sort(df_panel,dom_variable, n_quantiles)\n",
    "\n",
    "        # Compute the difference: H minus L\n",
    "        pivot = df_panel.pivot_table(index='WeekYear', columns='portfolio', values='ret')\n",
    "        pivot[\"CDOM\"] = pivot[f\"P{n_quantiles}\"] - pivot['P1']\n",
    "        dominance_factor = pivot[[\"CDOM\"]].reset_index()\n",
    "        assets_panel = clean_weekly_panel(reg_panel, dom_variable, is_stablecoin = 0, is_boom = -1)\n",
    "        # merge all factors\n",
    "        data_fama_macbeth = pd.merge(dominance_factor, ff3, on=[\"WeekYear\"], how=\"left\")\n",
    "        data_fama_macbeth = pd.merge(data_fama_macbeth, ltw3, on=[\"WeekYear\"], how=\"left\")\n",
    "        # merge factors with returns\n",
    "        data_fama_macbeth = pd.merge(data_fama_macbeth, assets_panel, on=[\"WeekYear\"], how=\"left\")\n",
    "        data_fama_macbeth = data_fama_macbeth.dropna()\n",
    "\n",
    "        # run the Fama-Macbeth regression\n",
    "        data_fama_macbeth['excess_ret'] = data_fama_macbeth['ret'] - data_fama_macbeth['RF']\n",
    "        fama_macbeth = reg_fama_macbeth(data_fama_macbeth, formula=\"excess_ret ~ CMKT + CMOM + CSIZE + CDOM\")\n",
    "        if is_boom == 1:\n",
    "            boom_str = \" boom\"\n",
    "        elif is_boom == 0:\n",
    "            boom_str = \" bust\"\n",
    "        else:\n",
    "            boom_str = \" alltime\"\n",
    "        fama_macbeth = fama_macbeth.style.set_caption(dom_variable + boom_str)\n",
    "        display(fama_macbeth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
